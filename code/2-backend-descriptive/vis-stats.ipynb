{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor, ceil\n",
    "from random import randint\n",
    "from statistics import mean\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"D:\\A李杜若\\留学\\科研\\可视化_王懿芳学姐\\CFPS\\NLS\\2-imputed-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening nlsw JSON file\n",
    "with open('psid_imputed.json') as json_file:\n",
    "    people_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5225"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(people_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None, 'college', 'high-school', 'high-school-noncompletion'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pd.DataFrame(list(pd.DataFrame(list(pd.DataFrame(people_dict)['basic_info']))['education']))['highest_education_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening nlsy79 JSON file\n",
    "with open('nlsy_imputed.json') as json_file:\n",
    "    people_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'basic_info': {'birth_year': 1959,\n",
       "  'education': {'highest_education_level': 'high-school',\n",
       "   'highest_education_name': '12th grade',\n",
       "   'year': 1978},\n",
       "  'first_job': {'income': 5000, 'occupation': 305, 'year': 1979},\n",
       "  'gender': 'female',\n",
       "  'race': 'other'},\n",
       " 'life_sequence': [{'child_under_18': False,\n",
       "   'child_under_18_status_change': -1,\n",
       "   'childbearing_status': False,\n",
       "   'income': 5000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'never married',\n",
       "   'marriage_status_change': -1,\n",
       "   'migration_status': -1,\n",
       "   'occupation': '305',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1979},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 6000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'never married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '305',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1980},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 10000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'never married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '305',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1981},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 11000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'never married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '305',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1982},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 11500,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'never married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '305',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1983},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 11000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'never married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '1',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1984},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 14000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'never married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '375',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1985},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 16000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'never married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '1',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1986},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 20000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'never married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '1',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1987},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 19000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'never married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '1',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1988},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 20000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'never married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '394',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1989},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 20000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'never married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '1',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1990},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 22000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'never married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '305',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1991},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 25000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': True,\n",
       "   'migration_status': False,\n",
       "   'occupation': '1',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1992},\n",
       "  {'child_under_18': True,\n",
       "   'child_under_18_status_change': 2,\n",
       "   'childbearing_status': True,\n",
       "   'income': 23375,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '305',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1993},\n",
       "  {'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': True,\n",
       "   'income': 21750,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '305',\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'year': 1994},\n",
       "  {'occupation': '305',\n",
       "   'income': 20125,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'childbearing_status': False,\n",
       "   'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'residence': 'SMSA, in central city',\n",
       "   'migration_status': False,\n",
       "   'year': 1995},\n",
       "  {'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 18500,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': True,\n",
       "   'occupation': '305',\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'year': 1996},\n",
       "  {'occupation': '305',\n",
       "   'income': 16875,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'childbearing_status': False,\n",
       "   'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'migration_status': False,\n",
       "   'year': 1997},\n",
       "  {'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 15250,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '305',\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'year': 1998},\n",
       "  {'occupation': '305',\n",
       "   'income': 13625,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'childbearing_status': False,\n",
       "   'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'migration_status': False,\n",
       "   'year': 1999},\n",
       "  {'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 12000,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '305',\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'year': 2000},\n",
       "  {'occupation': '305',\n",
       "   'income': 10375,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'childbearing_status': False,\n",
       "   'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'migration_status': False,\n",
       "   'year': 2001},\n",
       "  {'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 8750,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '305',\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'year': 2002},\n",
       "  {'occupation': '305',\n",
       "   'income': 7125,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'childbearing_status': False,\n",
       "   'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'migration_status': False,\n",
       "   'year': 2003},\n",
       "  {'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 5500,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '4720',\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'year': 2004},\n",
       "  {'occupation': '4720',\n",
       "   'income': 5250,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'childbearing_status': False,\n",
       "   'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'migration_status': False,\n",
       "   'year': 2005},\n",
       "  {'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 5000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '4720',\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'year': 2006},\n",
       "  {'occupation': '4720',\n",
       "   'income': 5500,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'childbearing_status': False,\n",
       "   'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'migration_status': False,\n",
       "   'year': 2007},\n",
       "  {'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 6000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '4720',\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'year': 2008},\n",
       "  {'occupation': '4720',\n",
       "   'income': 12500,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'childbearing_status': False,\n",
       "   'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'migration_status': False,\n",
       "   'year': 2009},\n",
       "  {'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 19000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '4720',\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'year': 2010},\n",
       "  {'occupation': '4720',\n",
       "   'income': 20000,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'childbearing_status': False,\n",
       "   'child_under_18': True,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'migration_status': False,\n",
       "   'year': 2011},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 1,\n",
       "   'childbearing_status': False,\n",
       "   'income': 21000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '4720',\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'year': 2012},\n",
       "  {'occupation': '4720',\n",
       "   'income': 22000,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'childbearing_status': False,\n",
       "   'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'migration_status': False,\n",
       "   'year': 2013},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 23000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '4720',\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'year': 2014},\n",
       "  {'occupation': '4720',\n",
       "   'income': 24000,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'childbearing_status': False,\n",
       "   'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'migration_status': False,\n",
       "   'year': 2015},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 25000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '4020',\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'year': 2016},\n",
       "  {'occupation': '4020',\n",
       "   'income': 25000,\n",
       "   'isWorking': False,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'childbearing_status': False,\n",
       "   'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'migration_status': False,\n",
       "   'year': 2017},\n",
       "  {'child_under_18': False,\n",
       "   'child_under_18_status_change': 0,\n",
       "   'childbearing_status': False,\n",
       "   'income': 25000,\n",
       "   'isWorking': True,\n",
       "   'marriage_status': 'married',\n",
       "   'marriage_status_change': False,\n",
       "   'migration_status': False,\n",
       "   'occupation': '4020',\n",
       "   'residence': 'SMSA, not in central city',\n",
       "   'year': 2018}],\n",
       " 'person_id': '2',\n",
       " 'spouse_info': {'spouse_birth_year': 1958,\n",
       "  'spouse_education': {'highest_education_level': 'high-school',\n",
       "   'highest_education_name': '12th grade',\n",
       "   'year': None},\n",
       "  'spouse_first_job': {'income': 120, 'occupation': None, 'year': 1979},\n",
       "  'spouse_id': 6443,\n",
       "  'spouse_life_sequence': [{'child_under_18': True,\n",
       "    'child_under_18_status_change': -1,\n",
       "    'childbearing_status': False,\n",
       "    'income': 120,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': -1,\n",
       "    'migration_status': -1,\n",
       "    'occupation': None,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1979},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': None,\n",
       "    'isWorking': False,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': None,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1980},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 1000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': None,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1981},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 5000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 663,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1982},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': True,\n",
       "    'income': 2000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 663,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1983},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 5200,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 663,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1984},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 6000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 663,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1985},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 8000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 663,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1986},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 8000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 663,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1987},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 8000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 663,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1988},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 7200,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 912,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1989},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 6000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 753,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1990},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 7000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 780,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1991},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 7000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 690,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1992},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 13000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 643,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1993},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 13000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 643,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1994},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 13000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 643,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1996},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 21000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 392,\n",
       "    'residence': 'not in SMSA',\n",
       "    'year': 1998},\n",
       "   {'child_under_18': True,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': None,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': True,\n",
       "    'occupation': 392,\n",
       "    'residence': 'SMSA, not in central city',\n",
       "    'year': 2000},\n",
       "   {'child_under_18': False,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': None,\n",
       "    'isWorking': False,\n",
       "    'marriage_status': None,\n",
       "    'marriage_status_change': None,\n",
       "    'migration_status': None,\n",
       "    'occupation': None,\n",
       "    'residence': None,\n",
       "    'year': 2002},\n",
       "   {'child_under_18': False,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': None,\n",
       "    'isWorking': False,\n",
       "    'marriage_status': None,\n",
       "    'marriage_status_change': None,\n",
       "    'migration_status': None,\n",
       "    'occupation': None,\n",
       "    'residence': None,\n",
       "    'year': 2004},\n",
       "   {'child_under_18': False,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 12000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': None,\n",
       "    'marriage_status_change': None,\n",
       "    'migration_status': None,\n",
       "    'occupation': None,\n",
       "    'residence': None,\n",
       "    'year': 2006},\n",
       "   {'child_under_18': False,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': None,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': None,\n",
       "    'migration_status': None,\n",
       "    'occupation': 4610,\n",
       "    'residence': 'SMSA, not in central city',\n",
       "    'year': 2008},\n",
       "   {'child_under_18': False,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': 20000,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 4610,\n",
       "    'residence': 'SMSA, not in central city',\n",
       "    'year': 2010},\n",
       "   {'child_under_18': False,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': None,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 4610,\n",
       "    'residence': 'SMSA, not in central city',\n",
       "    'year': 2012},\n",
       "   {'child_under_18': False,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': None,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 4610,\n",
       "    'residence': 'SMSA, not in central city',\n",
       "    'year': 2014},\n",
       "   {'child_under_18': False,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': None,\n",
       "    'isWorking': True,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': 4610,\n",
       "    'residence': 'SMSA, not in central city',\n",
       "    'year': 2016},\n",
       "   {'child_under_18': False,\n",
       "    'child_under_18_status_change': None,\n",
       "    'childbearing_status': False,\n",
       "    'income': None,\n",
       "    'isWorking': False,\n",
       "    'marriage_status': 'married',\n",
       "    'marriage_status_change': False,\n",
       "    'migration_status': False,\n",
       "    'occupation': None,\n",
       "    'residence': 'SMSA, not in central city',\n",
       "    'year': 2018}],\n",
       "  'spouse_race': 'black'},\n",
       " 'career_sequence_statistics': {'num_real_career_dot_occu': 23,\n",
       "  'num_real_career_dot_income': 22,\n",
       "  'num_continous_real_career_dot_occu': 15,\n",
       "  'num_continous_real_career_dot_income': 14,\n",
       "  'end_year': 2018,\n",
       "  'start_year': 1979,\n",
       "  'career_length': 40}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening nlsm JSON file\n",
    "with open('nlsm_imputed.json') as json_file:\n",
    "    people_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening psid JSON file\n",
    "with open('psid_imputed.json') as json_file:\n",
    "    people_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主函数-分块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('psid_imputed.json') as json_file:\n",
    "    people_dict = json.load(json_file)\n",
    "person_year_info =pd.read_csv('psid-person-year-combine.csv')\n",
    "person_year_info[person_year_info<0]=-1\n",
    "df_people_occu_level = pd.read_csv('psid_industry_info.csv', index_col='Unnamed: 0')\n",
    "df_people_occu_level.index = df_people_occu_level.index.astype('string')\n",
    "df_industry = pd.read_csv('psid_industry_change_abs.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            1001\n",
       "1            1002\n",
       "2            1002\n",
       "3            1002\n",
       "4            1002\n",
       "           ...   \n",
       "432765    9308002\n",
       "432766    9308002\n",
       "432767    9308002\n",
       "432768    9308002\n",
       "432769    9308002\n",
       "Name: person_id, Length: 432770, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_year_info['person_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>year</th>\n",
       "      <th>age</th>\n",
       "      <th>occu_change</th>\n",
       "      <th>industry_change</th>\n",
       "      <th>income_quantile_upward</th>\n",
       "      <th>income_quantile_downward</th>\n",
       "      <th>have child(ren) under 18_to_have no child under 18</th>\n",
       "      <th>have no child under 18_to_have child(ren) under 18</th>\n",
       "      <th>migration</th>\n",
       "      <th>marrital_status-single_to_couple</th>\n",
       "      <th>marrital_status-couple_to_single</th>\n",
       "      <th>marrital_status-single_to_single</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1001</td>\n",
       "      <td>1968</td>\n",
       "      <td>52</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>1970</td>\n",
       "      <td>48</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>1971</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>1972</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>1973</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308002</th>\n",
       "      <td>9308002</td>\n",
       "      <td>2015</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308002</th>\n",
       "      <td>9308002</td>\n",
       "      <td>2016</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308002</th>\n",
       "      <td>9308002</td>\n",
       "      <td>2017</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308002</th>\n",
       "      <td>9308002</td>\n",
       "      <td>2018</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308002</th>\n",
       "      <td>9308002</td>\n",
       "      <td>2019</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432770 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           person_id  year  age  occu_change  industry_change  \\\n",
       "person_id                                                       \n",
       "1001            1001  1968   52           -1              NaN   \n",
       "1002            1002  1970   48           -1              NaN   \n",
       "1002            1002  1971   49            0              NaN   \n",
       "1002            1002  1972   50            0              NaN   \n",
       "1002            1002  1973   51            0              NaN   \n",
       "...              ...   ...  ...          ...              ...   \n",
       "9308002      9308002  2015   48            0              NaN   \n",
       "9308002      9308002  2016   49            0              NaN   \n",
       "9308002      9308002  2017   50            0              NaN   \n",
       "9308002      9308002  2018   51            0              NaN   \n",
       "9308002      9308002  2019   52            0              NaN   \n",
       "\n",
       "           income_quantile_upward  income_quantile_downward  \\\n",
       "person_id                                                     \n",
       "1001                           -1                        -1   \n",
       "1002                           -1                        -1   \n",
       "1002                            0                         0   \n",
       "1002                            0                         0   \n",
       "1002                            0                         0   \n",
       "...                           ...                       ...   \n",
       "9308002                         0                         0   \n",
       "9308002                         0                         0   \n",
       "9308002                         0                         0   \n",
       "9308002                         0                         0   \n",
       "9308002                         0                         0   \n",
       "\n",
       "           have child(ren) under 18_to_have no child under 18  \\\n",
       "person_id                                                       \n",
       "1001                                                      -1    \n",
       "1002                                                      -1    \n",
       "1002                                                       0    \n",
       "1002                                                       0    \n",
       "1002                                                       0    \n",
       "...                                                      ...    \n",
       "9308002                                                    0    \n",
       "9308002                                                    0    \n",
       "9308002                                                    0    \n",
       "9308002                                                    0    \n",
       "9308002                                                    0    \n",
       "\n",
       "           have no child under 18_to_have child(ren) under 18  migration  \\\n",
       "person_id                                                                  \n",
       "1001                                                      -1          -1   \n",
       "1002                                                      -1          -1   \n",
       "1002                                                       0           0   \n",
       "1002                                                       0           0   \n",
       "1002                                                       0           0   \n",
       "...                                                      ...         ...   \n",
       "9308002                                                    0           0   \n",
       "9308002                                                    0           0   \n",
       "9308002                                                    0           0   \n",
       "9308002                                                    0           0   \n",
       "9308002                                                    0           0   \n",
       "\n",
       "           marrital_status-single_to_couple  marrital_status-couple_to_single  \\\n",
       "person_id                                                                       \n",
       "1001                                     -1                                -1   \n",
       "1002                                     -1                                -1   \n",
       "1002                                      0                                 0   \n",
       "1002                                      0                                 0   \n",
       "1002                                      0                                 0   \n",
       "...                                     ...                               ...   \n",
       "9308002                                   0                                 0   \n",
       "9308002                                   0                                 0   \n",
       "9308002                                   0                                 0   \n",
       "9308002                                   0                                 0   \n",
       "9308002                                   0                                 0   \n",
       "\n",
       "           marrital_status-single_to_single  \n",
       "person_id                                    \n",
       "1001                                     -1  \n",
       "1002                                     -1  \n",
       "1002                                      0  \n",
       "1002                                      0  \n",
       "1002                                      0  \n",
       "...                                     ...  \n",
       "9308002                                   0  \n",
       "9308002                                   0  \n",
       "9308002                                   0  \n",
       "9308002                                   0  \n",
       "9308002                                   0  \n",
       "\n",
       "[432770 rows x 13 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_year_info.index = person_year_info['person_id']\n",
    "person_year_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>first_job</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1916</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1922</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': '5'}</td>\n",
       "      <td>{'year': None, 'highest_education_level': None...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1947</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>{'year': 1967, 'income': None, 'occupation': '7'}</td>\n",
       "      <td>{'year': None, 'highest_education_level': None...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1912</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1912</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': '7'}</td>\n",
       "      <td>{'year': None, 'highest_education_level': 'hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32083</th>\n",
       "      <td>1929</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': '7'}</td>\n",
       "      <td>{'year': None, 'highest_education_level': 'col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32084</th>\n",
       "      <td>1950</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': '7'}</td>\n",
       "      <td>{'year': None, 'highest_education_level': 'hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32085</th>\n",
       "      <td>1953</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': '9'}</td>\n",
       "      <td>{'year': 1975, 'highest_education_level': 'col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32086</th>\n",
       "      <td>1949</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': '7'}</td>\n",
       "      <td>{'year': None, 'highest_education_level': 'hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32087</th>\n",
       "      <td>1967</td>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': N...</td>\n",
       "      <td>{'year': None, 'highest_education_level': 'hig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32088 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       birth_year  gender   race  \\\n",
       "0            1916    male  white   \n",
       "1            1922  female  white   \n",
       "2            1947    male  white   \n",
       "3            1912    male  white   \n",
       "4            1912  female  white   \n",
       "...           ...     ...    ...   \n",
       "32083        1929    male  white   \n",
       "32084        1950    male  white   \n",
       "32085        1953    male  white   \n",
       "32086        1949  female  black   \n",
       "32087        1967  female  other   \n",
       "\n",
       "                                               first_job  \\\n",
       "0                                                    NaN   \n",
       "1      {'year': None, 'income': None, 'occupation': '5'}   \n",
       "2      {'year': 1967, 'income': None, 'occupation': '7'}   \n",
       "3                                                    NaN   \n",
       "4      {'year': None, 'income': None, 'occupation': '7'}   \n",
       "...                                                  ...   \n",
       "32083  {'year': None, 'income': None, 'occupation': '7'}   \n",
       "32084  {'year': None, 'income': None, 'occupation': '7'}   \n",
       "32085  {'year': None, 'income': None, 'occupation': '9'}   \n",
       "32086  {'year': None, 'income': None, 'occupation': '7'}   \n",
       "32087  {'year': None, 'income': None, 'occupation': N...   \n",
       "\n",
       "                                               education  \n",
       "0                                                    NaN  \n",
       "1      {'year': None, 'highest_education_level': None...  \n",
       "2      {'year': None, 'highest_education_level': None...  \n",
       "3                                                    NaN  \n",
       "4      {'year': None, 'highest_education_level': 'hig...  \n",
       "...                                                  ...  \n",
       "32083  {'year': None, 'highest_education_level': 'col...  \n",
       "32084  {'year': None, 'highest_education_level': 'hig...  \n",
       "32085  {'year': 1975, 'highest_education_level': 'col...  \n",
       "32086  {'year': None, 'highest_education_level': 'hig...  \n",
       "32087  {'year': None, 'highest_education_level': 'hig...  \n",
       "\n",
       "[32088 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(pd.DataFrame(people_dict)['basic_info']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{True: 0.9641825534373195, False: 0.03581744656268053}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_people_occu_level.apply(lambda x: len(set(x))>1, axis=1).value_counts(normalize=True).to_dict()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0874810718282968"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_industry[df_industry>0].sum().sum())/(df_industry.shape[0]*df_industry.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.DataFrame(list(pd.DataFrame(people_dict)['basic_info'])).set_index(pd.Index(pd.DataFrame(people_dict)['person_id']))\n",
    "lll = list(dd[dd['gender']=='male'].index)\n",
    "d1.loc[list(dd[dd['gender']=='male'].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2063722196683051"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_percent(x):\n",
    "    per = 1-(x>0).value_counts(normalize=True)[False]\n",
    "    return per\n",
    "count_percent(person_year_info['occu_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nlsy_imputed.json') as json_file:\n",
    "    people_dict0 = json.load(json_file)\n",
    "dd = pd.DataFrame(list(pd.DataFrame(people_dict0)['basic_info'])).set_index(pd.Index(pd.DataFrame(people_dict0)['person_id']))\n",
    "f_id_list = list(dd[dd['gender']=='female'].index)\n",
    "m_id_list = list(dd[dd['gender']=='male'].index)\n",
    "g_id_lists = [m_id_list, f_id_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts(normalize=True).apply(lambda x: format(x,'.4f')).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1979: {False: 1.0, True: 0.0},\n",
       " 1980: {False: 0.7541, True: 0.2459},\n",
       " 1981: {False: 0.7964, True: 0.2036},\n",
       " 1982: {False: 0.7931, True: 0.2069},\n",
       " 1983: {False: 0.8263, True: 0.1737},\n",
       " 1984: {False: 0.8264, True: 0.1736},\n",
       " 1985: {False: 0.8329, True: 0.1671},\n",
       " 1986: {False: 0.8408, True: 0.1592},\n",
       " 1987: {False: 0.8703, True: 0.1297},\n",
       " 1988: {False: 0.8527, True: 0.1473},\n",
       " 1989: {False: 0.8855, True: 0.1145},\n",
       " 1990: {False: 0.8848, True: 0.1152},\n",
       " 1991: {False: 0.8934, True: 0.1066},\n",
       " 1992: {False: 0.8925, True: 0.1075},\n",
       " 1993: {False: 0.8902, True: 0.1098},\n",
       " 1994: {False: 0.8769, True: 0.1231},\n",
       " 1995: {False: 0.9226, True: 0.0774},\n",
       " 1996: {False: 0.9269, True: 0.0731},\n",
       " 1997: {False: 0.9341, True: 0.0659},\n",
       " 1998: {False: 0.9365, True: 0.0635},\n",
       " 1999: {False: 0.9264, True: 0.0736},\n",
       " 2000: {False: 0.9398, True: 0.0602},\n",
       " 2001: {False: 0.9288, True: 0.0712},\n",
       " 2002: {False: 0.9431, True: 0.0569},\n",
       " 2003: {False: 0.9343, True: 0.0657},\n",
       " 2004: {False: 0.9457, True: 0.0543},\n",
       " 2005: {False: 0.9373, True: 0.0627},\n",
       " 2006: {False: 0.9455, True: 0.0545},\n",
       " 2007: {False: 0.9465, True: 0.0535},\n",
       " 2008: {False: 0.9383, True: 0.0617},\n",
       " 2009: {False: 0.9476, True: 0.0524},\n",
       " 2010: {False: 0.9537, True: 0.0463},\n",
       " 2011: {False: 0.9385, True: 0.0615},\n",
       " 2012: {False: 0.9551, True: 0.0449},\n",
       " 2013: {False: 0.9601, True: 0.0399},\n",
       " 2014: {False: 0.9556, True: 0.0444},\n",
       " 2015: {False: 0.9614, True: 0.0386},\n",
       " 2016: {False: 0.9605, True: 0.0395},\n",
       " 2017: {False: 1.0, True: 0.0},\n",
       " 2018: {False: 1.0, True: 0.0}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'nlsy'\n",
    "person_year_info0 =pd.read_csv(dataset + '-person-year-combine.csv').set_index('person_id', drop=False)\n",
    "person_year_info0.index = person_year_info0.index.astype('string')\n",
    "def count_percent(x):\n",
    "    per = (x>0).value_counts(normalize=True).round(4).to_dict()\n",
    "    return per\n",
    "person_year_info0['income_quantile_upward'].groupby(person_year_info0['year']).apply(lambda x:count_percent(x)).fillna(0).unstack().to_dict(orient ='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_id\n",
       "1       -12\n",
       "1         0\n",
       "1         0\n",
       "1         0\n",
       "1         0\n",
       "         ..\n",
       "12686     0\n",
       "12686     0\n",
       "12686     0\n",
       "12686     0\n",
       "12686     0\n",
       "Length: 376588, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_year_info0[['central_nocentral', 'nocentral_central', 'other_migration']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlsw(1968)\n",
    "# 68-93: 60 codes\n",
    "w_60_start = 0\n",
    "w_60_end = 1994-1968\n",
    "bin_60_3 = [0,195,199,222,249,290,300,370,379,395,400,545,600,775,800,804,809,890,900,905,959,985,994,995]\n",
    "# 95-01: 90 codes\n",
    "w_90_start = 1995-1968\n",
    "w_90_end = 2002-1968\n",
    "bin_90_3 = [3,22,37,42,199,202,235,242,285,302,389,402,407,412,427,432,469,472,476,484,499,502,699,702,889,996,997,998]\n",
    "# 03: 00 codes\n",
    "w_00 = 2003-1968\n",
    "bin_00_3 = [1,43,49,95,99,124,129,156,159,196,199,206,209,215,219,255,259,296,299,354,359,365,369,395,399,416,419,425,429,465,469,496,499,593,599,613,619,694,699,762,769,896,899,975,983,984,996,997,998]\n",
    "\n",
    "# nlsy(1979)\n",
    "# 79-00: 3 digit, 70 code,\n",
    "y_70_start = 0\n",
    "y_70_end = 2001-1979\n",
    "bin_70_3 = [1 , 195,200 , 245,259 , 285,300 , 395, 400 , 575,600 , 715,739 , 785,800 , 802,820 , 824,900 , 965, 979 , 984]\n",
    "# 02: 3-digit, 00 code\n",
    "y_00_3_start = 2002-1979\n",
    "y_00_3_end = 2003-1979\n",
    "\n",
    "# 04-18: 4 digit, 00 code\n",
    "y_00_4_start = 2004-1979\n",
    "y_00_4_end = 2018-1979\n",
    "bin_00_4 = [10 , 430, 500 -1, 950,1000-1 , 1240,1300 -1, 1560,1600 -1, 1760,1800 -1, 1860,1900 -1, 1960,2000-1 , 2060, 2100 -1, 2150,2200 -1, 2340,2400 -1, 2550, 2600 -1, 2760,2800 -1, 2960,3000-1 , 3260, 3300 -1, 3650,3700 -1, 3950,4000-1 , 4160,4200 -1, 4250,4300 -1, 4430,4459,4460, 4500 -1, 4650,4700 -1, 4960,5000-1 , 5930,6000-1 , 6130,6200 -1, 6940,7000-1 , 7620,7700 -1, 7750,7800 -1, 7850,7900 -1, 8960,9000-1 , 9750,9800 -1, 9830,9839,9840,9949,9950,9989,9990]\n",
    "\n",
    "# nlsm(1966)\n",
    "# 3-digit 60codes\n",
    "\n",
    "# psid更新过的occupation(1968)\n",
    "# 1968-2001: 1970 3-digit code, \n",
    "p_70_start = 0\n",
    "p_70_end = 2001-1968\n",
    "# 2002-2015: 2000 3-digit code,\n",
    "p_00_start = 2002-1968\n",
    "p_00_end = 2016-1968\n",
    "# 2017-2019: 2010 4-digit code\n",
    "p_10_start = 2017-1968\n",
    "p_10_end = 2019-1968\n",
    "bin_10_4 = [10 , 430, 500 -1, 950,1000-1 , 1240,1300 -1, 1560,1600 -1, 1965,2000-1 , 2060, 2100 -1, 2160,2200 -1, 2550, 2600 -1, 2960,3000-1 , 3540, 3600 -1, 3650,3700 -1, 3955,4000-1 , 4160,4200 -1, 4250,4300 -1, 4650,4700 -1, 4965,5000-1 , 5940,6005-1 , 6130,6200 -1, 6940,7700-1 , 8965,9000-1 , 9750,9800 -1, 9830,9998,9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('psid_imputed.json') as json_file:\n",
    "    people_dict0 = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##划分记录出生年代（区间）\n",
    "dd = pd.DataFrame(list(pd.DataFrame(people_dict0)['basic_info'])).set_index(pd.Index(pd.DataFrame(people_dict0)['person_id']))\n",
    "start_bir = 1900\n",
    "end_bir = 10*ceil((dd['birth_year'].describe()['max']-1900)/10)+1900\n",
    "dd['birth_year_range'] = pd.cut(dd['birth_year'], [i for i in range(start_bir,end_bir+10,10)], right=False,labels=[f'{i}s' for i in range(start_bir,end_bir,10)]).cat.add_categories([\"none\"]).fillna(\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_dictionary(dataset):\n",
    "    with open(dataset + '_imputed.json') as json_file:\n",
    "        people_dict0 = json.load(json_file)\n",
    "    person_year_info0 =pd.read_csv(dataset + '-person-year-combine.csv').set_index('person_id', drop=False)\n",
    "    person_year_info0.index = person_year_info0.index.astype('string')\n",
    "    person_year_info0.index.name = None\n",
    "    if dataset == 'nlsy':\n",
    "        person_year_info0['migration']= person_year_info0[['central_nocentral', 'nocentral_central', 'other_migration']].sum(axis=1)\n",
    "        person_year_info0[person_year_info0<0]=-1\n",
    "\n",
    "    df_people_indu_level0 = pd.read_csv(dataset + '_industry_info.csv', index_col='Unnamed: 0')\n",
    "    df_people_indu_level0.index = df_people_indu_level0.index.astype('string')\n",
    "    df_industry0 = pd.read_csv(dataset + '_industry_change_abs.csv', index_col='Unnamed: 0')\n",
    "    df_industry0.index = df_industry0.index.astype('string')\n",
    "    ### 0.准备\n",
    "    separate_dict = {\n",
    "        \"dataset_size\":5000,\n",
    "        \"group_statistics\":[] \n",
    "    }   \n",
    "    ## 储存'male','female','other'分别的stats_dict\n",
    "    stats_dict_list = []\n",
    "    gender_list = ['male','female']\n",
    "    ## 储存female和male的 person_id\n",
    "    dd = pd.DataFrame(list(pd.DataFrame(people_dict0)['basic_info'])).set_index(pd.Index(pd.DataFrame(people_dict0)['person_id']))\n",
    "\n",
    "    if dataset == \"nlsw\":\n",
    "        f_id_list = list(dd.index)\n",
    "        m_id_list = []\n",
    "    elif dataset == 'nlsm':\n",
    "        f_id_list = []\n",
    "        m_id_list = list(dd.index)\n",
    "    else:\n",
    "        f_id_list = list(dd[dd['gender']=='female'].index)\n",
    "        m_id_list = list(dd[dd['gender']=='male'].index)\n",
    "    g_id_lists = [m_id_list, f_id_list]\n",
    "        \n",
    "    ## 获取dataset_size\n",
    "    total_num = len(people_dict0)\n",
    "    separate_dict['dataset_size'] = total_num\n",
    "    \n",
    "    for g_idx, gender in enumerate(gender_list):\n",
    "        if (dataset == 'nlsw' and gender == 'male') or (dataset == 'nlsm' and gender == 'female'):\n",
    "            continue\n",
    "\n",
    "        # 每次都要重新创建新的dict，不然会连为一体\n",
    "        stats_dict = {\n",
    "        \"individual_unit\": {\n",
    "            \"demographic\": {\n",
    "                \"gender\": {\"male\": 0.45, \"female\": 0.5, \"others\": 0.05},\n",
    "                \"race\": {\"white\": 0.6, \"black\": 0.35, \"others\": 0.05}, \n",
    "                \"birth_year\": {\"70\": 0.45, \"80\": 0.35, \"90\": 0.2},\n",
    "                \"education_level\": {\"high-school-noncompletion\": 0.5, \"high-school\": 0.3, \"college\": 0.15, \"none\": 0.05}, \n",
    "            },\n",
    "            \"work\": {  # 这个人至少发生一次如下event，就计数为1。统计label为1的人数占总人数的百分比\n",
    "                \"ever_income_upward_mobility\": 0.01,\n",
    "                \"ever_occu_change\": 0.002,\n",
    "                \"ever_industry_change\": 0.003\n",
    "            },\n",
    "            \"life\": {\n",
    "                \"ever_married\": 0.6,\n",
    "                \"ever_have_child\": 0.4,\n",
    "                \"ever_migrated\": 0.2\n",
    "            }\n",
    "        },\n",
    "        \"person_year_unit\": {\n",
    "            \"work\": {\n",
    "                \"income_upward_mobility\": 0.001,\n",
    "                \"income_downward_mobility\": 0.001,\n",
    "                \"occu_change\": 0.002,\n",
    "                \"industry_change\": 0.003\n",
    "            },\n",
    "            \"life\": {\n",
    "                # 1. transfer events\n",
    "                \"single_couple\": 0.02,\n",
    "                \"couple_single\": 0.01,\n",
    "                \"childbearing_no_yes\": 0.01,\n",
    "            },\n",
    "            \"income_upward_mobility_trend\": {\n",
    "                \"relative_time\": {\n",
    "                    \"1\": 0.02, # 含义：工作第1年，相比于工作第0年，发生upward mobility的人占所有人数的百分之多少\n",
    "                    \"2\": 0.04,\n",
    "                    \n",
    "                },\n",
    "                \"absolute_time\": {\n",
    "                    \"1966\": 0.05, # 含义：1966年发生upward mobility的人占所有人数的百分之多少\n",
    "                    \"1967\": 0.06,\n",
    "                    \n",
    "                }\n",
    "            }, \n",
    "            \"income_downward_mobility_trend\": {\n",
    "                \"relative_time\": {\n",
    "                    \"1\": 0.02, \n",
    "                    \"2\": 0.04,\n",
    "                    \n",
    "                },\n",
    "                \"absolute_time\": {\n",
    "                    \"1966\": 0.05, \n",
    "                    \"1967\": 0.06,\n",
    "                    \n",
    "                }\n",
    "            }, \n",
    "        }\n",
    "    }\n",
    "        g_id_list = g_id_lists[g_idx]\n",
    "        stats_dict['group_name']=gender\n",
    "        \n",
    "        ### 1.individual_unit\n",
    "        # 获取指定性别的 people_dict\n",
    "        people_dict = [person for person in people_dict0 if person['person_id'] in g_id_list]\n",
    "        df_demo = pd.DataFrame(list(pd.DataFrame(people_dict)['basic_info']))\n",
    "        # 获取指定性别的 person_year_info\n",
    "        person_year_info = person_year_info0.loc[person_year_info0.index.intersection(g_id_list)]\n",
    "        # 获取指定性别的industry info\n",
    "        df_people_indu_level = df_people_indu_level0.loc[df_people_indu_level0.index.intersection(g_id_list)]\n",
    "        df_industry = df_industry0.loc[df_industry0.index.intersection(g_id_list)]\n",
    "        \n",
    "        # rank是为了绝对对齐\n",
    "        cumm = 0\n",
    "        person_year_info['rank']=0\n",
    "        for idx, length  in enumerate(person_year_info.groupby('person_id').size()):\n",
    "            person_year_info['rank'][cumm:cumm+length]=range(length)\n",
    "            cumm = cumm+length\n",
    "            \n",
    "        ## 1.1 demographic\n",
    "        # gender\n",
    "        if dataset == 'nlsw':\n",
    "            stats_dict['individual_unit']['demographic']['gender']={\"male\": 0, \"female\": 1, \"others\": 0}\n",
    "        elif dataset == 'nlsm':\n",
    "            stats_dict['individual_unit']['demographic']['gender']={\"male\": 1, \"female\": 0, \"others\": 0}\n",
    "        else:\n",
    "            stats_dict['individual_unit']['demographic']['gender'] = df_demo['gender'].fillna('none').value_counts(normalize=True).round(4).to_dict()\n",
    "        # race\n",
    "        stats_dict['individual_unit']['demographic']['race'] = df_demo['race'].fillna('none').value_counts(normalize=True).round(4).to_dict()\n",
    "        # birth_year\n",
    "        ## 计算年代范围\n",
    "        start_bir = 10*int((df_demo['birth_year'][df_demo['birth_year']>1200].describe()['min']-1800)/10)+1800\n",
    "        end_bir = 10*ceil((df_demo['birth_year'].describe()['max']-1900)/10)+1900\n",
    "        if dataset == 'nlsy':\n",
    "            stats_dict['individual_unit']['demographic']['birth_year'] = pd.cut(df_demo['birth_year'].fillna(\"none\"), [i for i in range(start_bir,end_bir+10,10)], right=False,labels=[f'{i}s' for i in range(start_bir,end_bir,10)]).value_counts(normalize=True).round(4).to_dict()\n",
    "        else:\n",
    "            stats_dict['individual_unit']['demographic']['birth_year'] = pd.cut(df_demo['birth_year'], [i for i in range(start_bir,end_bir+10,10)], right=False,labels=[f'{i}s' for i in range(start_bir,end_bir,10)]).cat.add_categories([\"none\"]).fillna(\"none\").value_counts(normalize=True).round(4).to_dict()\n",
    "        #education_level\n",
    "        stats_dict['individual_unit']['demographic']['education_level'] = pd.DataFrame(list(df_demo['education'].dropna()))['highest_education_level'].fillna('none').value_counts(normalize=True).round(4).to_dict()\n",
    "\n",
    "        ## 1.2 work\n",
    "        # ever_income_upward_mobility\n",
    "        stats_dict['individual_unit']['work']['ever_income_upward_mobility'] = person_year_info['income_quantile_upward'].groupby(person_year_info['person_id']).apply(lambda x: x.max()>0).value_counts(normalize=True).round(4).to_dict() #x.max()>0判断是否存在1，事件是否发生过\n",
    "        # ever_occu_change\n",
    "        stats_dict['individual_unit']['work']['ever_occu_change'] = person_year_info['occu_change'].groupby(person_year_info['person_id']).apply(lambda x: x.max()>0).value_counts(normalize=True).round(4).to_dict()\n",
    "        # ever_industry_change\n",
    "        if dataset == 'psid':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x[p_70_start:p_70_end+1]))+len(set(x[p_00_start:p_00_end+1]))+len(set(x[p_10_start:p_10_end+1]))>3, axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "        if dataset == 'nlsy':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x[y_70_start:y_70_end+1]))+len(set(x[y_00_4_start:y_00_4_end+1]))>2, axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "        if dataset == 'nlsw':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x[w_60_start:w_60_end+1]))+len(set(x[w_90_start:w_90_end+1]))>2, axis=1).value_counts(normalize=True).round(4).to_dict()    \n",
    "        if dataset == 'nlsm':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x))>1, axis=1).value_counts(normalize=True).round(4).to_dict()     \n",
    "        #len(set(x[y_70_start:y_70_end+1]))+len(set(x[y_00_4_start:y_00_4_end+1]))\n",
    "        ## 1.3 life\n",
    "        # 定义提取life_sequence序列的函数\n",
    "        def everfun(row, colname):\n",
    "            if list(filter(None, row))==[]:\n",
    "                return 'none'\n",
    "            elif pd.DataFrame(list(filter(None, list(row))))[colname].max()>0:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        df_life = pd.DataFrame(people_dict[0]['life_sequence'])\n",
    "        # ever_married\n",
    "        stats_dict['individual_unit']['life']['ever_married'] = pd.DataFrame(list(pd.DataFrame(people_dict)['life_sequence'])).apply(lambda row: everfun(row, 'marriage_status_change'), axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "\n",
    "        stats_dict['individual_unit']['life']['ever_have_child'] = pd.DataFrame(list(pd.DataFrame(people_dict)['life_sequence'])).apply(lambda row: everfun(row, 'child_under_18'), axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "        # ever_migrated\n",
    "        stats_dict['individual_unit']['life']['ever_migrated'] = pd.DataFrame(list(pd.DataFrame(people_dict)['life_sequence'])).apply(lambda row: everfun(row, 'migration_status'), axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "\n",
    "        ### person_year_unit\n",
    "        def count_percent(x):\n",
    "            per = (x>0).value_counts(normalize=True).round(4).to_dict()\n",
    "            return per\n",
    "        ## work\n",
    "        stats_dict['person_year_unit']['work']['income_upward_mobility'] = count_percent(person_year_info['income_quantile_upward'])\n",
    "        stats_dict['person_year_unit']['work']['income_downward_mobility'] = count_percent(person_year_info['income_quantile_downward'])\n",
    "        stats_dict['person_year_unit']['work']['occu_change'] = count_percent(person_year_info['occu_change'])\n",
    "        # industry_change（特殊）\n",
    "        stats_dict['person_year_unit']['work']['industry_change'] = {\"true\":0, \"false\":0}\n",
    "        stats_dict['person_year_unit']['work']['industry_change'][\"true\"] = round((df_industry[df_industry>0].sum().sum())/(df_industry.shape[0]*df_industry.shape[1]), 4)\n",
    "        stats_dict['person_year_unit']['work']['industry_change'][\"false\"] = 1-stats_dict['person_year_unit']['work']['industry_change'][\"true\"]\n",
    "        ## life\n",
    "        if dataset == 'nlsy':\n",
    "            lfe_trans_list = ['have child(ren) under 18_to_have no child under 18',\n",
    "            'have no child under 18_to_have child(ren) under 18', 'migration', 'central_nocentral', 'nocentral_central', 'other_migration',\n",
    "            'marrital_status-single_to_couple', 'marrital_status-couple_to_single',\n",
    "            'marrital_status-single_to_single']\n",
    "            lfe_name_list = ['childbearing_yes_no','childbearing_no_yes', 'has_migration', 'central_nocentral', 'nocentral_central', 'other_migration','single_couple', 'couple_single', 'single_single']\n",
    "        else:\n",
    "            lfe_trans_list = ['have child(ren) under 18_to_have no child under 18',\n",
    "            'have no child under 18_to_have child(ren) under 18', 'migration',\n",
    "            'marrital_status-single_to_couple', 'marrital_status-couple_to_single',\n",
    "            'marrital_status-single_to_single']\n",
    "            lfe_name_list = ['childbearing_yes_no','childbearing_no_yes', 'has_migration', 'single_couple', 'couple_single', 'single_single']\n",
    "            \n",
    "        for idx, event in enumerate(lfe_trans_list):\n",
    "            stats_dict['person_year_unit']['life'][lfe_name_list[idx]] = count_percent(person_year_info[event])\n",
    "        ## income_upward_mobility_trend\n",
    "        # relative_time\n",
    "        stats_dict['person_year_unit']['income_upward_mobility_trend']['relative_time'] = person_year_info['income_quantile_upward'].groupby(person_year_info['rank']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "        # absolute_time\n",
    "        stats_dict['person_year_unit']['income_upward_mobility_trend']['absolute_time'] = person_year_info['income_quantile_upward'].groupby(person_year_info['year']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "\n",
    "        ## income_downward_mobility_trend\n",
    "        # relative_time\n",
    "        stats_dict['person_year_unit']['income_downward_mobility_trend']['relative_time'] = person_year_info['income_quantile_downward'].groupby(person_year_info['rank']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "        # absolute_time\n",
    "        stats_dict['person_year_unit']['income_downward_mobility_trend']['absolute_time'] = person_year_info['income_quantile_downward'].groupby(person_year_info['year']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "\n",
    "    \n",
    "        stats_dict_list.append(stats_dict)\n",
    "        \n",
    "    separate_dict[\"group_statistics\"] = stats_dict_list   \n",
    "    ### 输出\n",
    "    with open('D:/A李杜若/留学/科研/可视化_王懿芳学姐/CFPS/NLS/4-descriptive-stats/'+dataset+'-stats-1.json', 'w') as f:\n",
    "        json.dump(separate_dict,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### race-group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_dictionary(dataset):\n",
    "    with open(dataset + '_imputed.json') as json_file:\n",
    "        people_dict0 = json.load(json_file)\n",
    "    person_year_info0 =pd.read_csv(dataset + '-person-year-combine.csv').set_index('person_id', drop=False)\n",
    "    person_year_info0.index = person_year_info0.index.astype('string')\n",
    "    person_year_info0.index.name = None\n",
    "    if dataset == 'nlsy':\n",
    "        person_year_info0['migration']= person_year_info0[['central_nocentral', 'nocentral_central', 'other_migration']].sum(axis=1)\n",
    "        person_year_info0[person_year_info0<0]=-1\n",
    "\n",
    "    df_people_indu_level0 = pd.read_csv(dataset + '_industry_info.csv', index_col='Unnamed: 0')\n",
    "    df_people_indu_level0.index = df_people_indu_level0.index.astype('string')\n",
    "    df_industry0 = pd.read_csv(dataset + '_industry_change_abs.csv', index_col='Unnamed: 0')\n",
    "    df_industry0.index = df_industry0.index.astype('string')\n",
    "    ### 0.准备\n",
    "    separate_dict = {\n",
    "        \"dataset_size\":5000,\n",
    "        \"group_statistics\":[] \n",
    "    }   \n",
    "    ## 储存'white','black','other'分别的stats_dict\n",
    "    stats_dict_list = []\n",
    "    race_list = ['white', 'black', 'other']\n",
    "    ## 储存person_id\n",
    "    dd = pd.DataFrame(list(pd.DataFrame(people_dict0)['basic_info'])).set_index(pd.Index(pd.DataFrame(people_dict0)['person_id']))\n",
    "\n",
    "    # if dataset == \"nlsw\":\n",
    "    #     w_id_list = list(dd.index)\n",
    "    #     b_id_list = []\n",
    "    # elif dataset == 'nlsm':\n",
    "    #     f_id_list = []\n",
    "    #     m_id_list = list(dd.index)\n",
    "    # else:\n",
    "    w_id_list = list(dd[dd['race']=='white'].index)\n",
    "    b_id_list = list(dd[dd['race']=='black'].index)\n",
    "    o_id_list = list(dd[dd['race']=='other'].index)\n",
    "    r_id_lists = [w_id_list, b_id_list, o_id_list]\n",
    "        \n",
    "    ## 获取dataset_size\n",
    "    total_num = len(people_dict0)\n",
    "    separate_dict['dataset_size'] = total_num\n",
    "    \n",
    "    for r_idx, race in enumerate(race_list):\n",
    "        # if (dataset == 'nlsw' and race == 'male') or (dataset == 'nlsm' and race == 'female'):\n",
    "        #     continue\n",
    "\n",
    "        # 每次都要重新创建新的dict，不然会连为一体\n",
    "        stats_dict = {\n",
    "        \"individual_unit\": {\n",
    "            \"demographic\": {\n",
    "                \"gender\": {\"male\": 0.45, \"female\": 0.5, \"others\": 0.05},\n",
    "                \"race\": {\"white\": 0.6, \"black\": 0.35, \"others\": 0.05}, \n",
    "                \"birth_year\": {\"70\": 0.45, \"80\": 0.35, \"90\": 0.2},\n",
    "                \"education_level\": {\"high-school-noncompletion\": 0.5, \"high-school\": 0.3, \"college\": 0.15, \"none\": 0.05}, \n",
    "            },\n",
    "            \"work\": {  # 这个人至少发生一次如下event，就计数为1。统计label为1的人数占总人数的百分比\n",
    "                \"ever_income_upward_mobility\": 0.01,\n",
    "                \"ever_occu_change\": 0.002,\n",
    "                \"ever_industry_change\": 0.003\n",
    "            },\n",
    "            \"life\": {\n",
    "                \"ever_married\": 0.6,\n",
    "                \"ever_have_child\": 0.4,\n",
    "                \"ever_migrated\": 0.2\n",
    "            }\n",
    "        },\n",
    "        \"person_year_unit\": {\n",
    "            \"work\": {\n",
    "                \"income_upward_mobility\": 0.001,\n",
    "                \"income_downward_mobility\": 0.001,\n",
    "                \"occu_change\": 0.002,\n",
    "                \"industry_change\": 0.003\n",
    "            },\n",
    "            \"life\": {\n",
    "                # 1. transfer events\n",
    "                \"single_couple\": 0.02,\n",
    "                \"couple_single\": 0.01,\n",
    "                \"childbearing_no_yes\": 0.01,\n",
    "            },\n",
    "            \"income_upward_mobility_trend\": {\n",
    "                \"relative_time\": {\n",
    "                    \"1\": 0.02, # 含义：工作第1年，相比于工作第0年，发生upward mobility的人占所有人数的百分之多少\n",
    "                    \"2\": 0.04,\n",
    "                    \n",
    "                },\n",
    "                \"absolute_time\": {\n",
    "                    \"1966\": 0.05, # 含义：1966年发生upward mobility的人占所有人数的百分之多少\n",
    "                    \"1967\": 0.06,\n",
    "                    \n",
    "                }\n",
    "            }, \n",
    "            \"income_downward_mobility_trend\": {\n",
    "                \"relative_time\": {\n",
    "                    \"1\": 0.02, \n",
    "                    \"2\": 0.04,\n",
    "                    \n",
    "                },\n",
    "                \"absolute_time\": {\n",
    "                    \"1966\": 0.05, \n",
    "                    \"1967\": 0.06,\n",
    "                    \n",
    "                }\n",
    "            }, \n",
    "        }\n",
    "    }\n",
    "        r_id_list = r_id_lists[r_idx]\n",
    "        stats_dict['group_name']=race\n",
    "        \n",
    "        ### 1.individual_unit\n",
    "        # 获取指定性别的 people_dict\n",
    "        people_dict = [person for person in people_dict0 if person['person_id'] in r_id_list]\n",
    "        df_demo = pd.DataFrame(list(pd.DataFrame(people_dict)['basic_info']))\n",
    "        # 获取指定性别的 person_year_info\n",
    "        person_year_info = person_year_info0.loc[person_year_info0.index.intersection(r_id_list)]\n",
    "        # 获取指定性别的industry info\n",
    "        df_people_indu_level = df_people_indu_level0.loc[df_people_indu_level0.index.intersection(r_id_list)]\n",
    "        df_industry = df_industry0.loc[df_industry0.index.intersection(r_id_list)]\n",
    "        \n",
    "        # rank是为了绝对对齐\n",
    "        cumm = 0\n",
    "        person_year_info['rank']=0\n",
    "        for idx, length  in enumerate(person_year_info.groupby('person_id').size()):\n",
    "            person_year_info['rank'][cumm:cumm+length]=range(length)\n",
    "            cumm = cumm+length\n",
    "            \n",
    "        ## 1.1 demographic\n",
    "        # gender\n",
    "        if dataset == 'nlsw':\n",
    "            stats_dict['individual_unit']['demographic']['gender']={\"male\": 0, \"female\": 1, \"others\": 0}\n",
    "        elif dataset == 'nlsm':\n",
    "            stats_dict['individual_unit']['demographic']['gender']={\"male\": 1, \"female\": 0, \"others\": 0}\n",
    "        else:\n",
    "            stats_dict['individual_unit']['demographic']['gender'] = df_demo['gender'].fillna('none').value_counts(normalize=True).round(4).to_dict()\n",
    "        # race\n",
    "        stats_dict['individual_unit']['demographic']['race'] = df_demo['race'].fillna('none').value_counts(normalize=True).round(4).to_dict()\n",
    "        # birth_year\n",
    "        ## 计算年代范围\n",
    "        start_bir = 10*int((df_demo['birth_year'][df_demo['birth_year']>1200].describe()['min']-1800)/10)+1800\n",
    "        end_bir = 10*ceil((df_demo['birth_year'].describe()['max']-1900)/10)+1900\n",
    "        if dataset == 'nlsy':\n",
    "            stats_dict['individual_unit']['demographic']['birth_year'] = pd.cut(df_demo['birth_year'].fillna(\"none\"), [i for i in range(start_bir,end_bir+10,10)], right=False,labels=[f'{i}s' for i in range(start_bir,end_bir,10)]).value_counts(normalize=True).round(4).to_dict()\n",
    "        else:\n",
    "            stats_dict['individual_unit']['demographic']['birth_year'] = pd.cut(df_demo['birth_year'], [i for i in range(start_bir,end_bir+10,10)], right=False,labels=[f'{i}s' for i in range(start_bir,end_bir,10)]).cat.add_categories([\"none\"]).fillna(\"none\").value_counts(normalize=True).round(4).to_dict()\n",
    "        #education_level\n",
    "        stats_dict['individual_unit']['demographic']['education_level'] = pd.DataFrame(list(df_demo['education'].dropna()))['highest_education_level'].fillna('none').value_counts(normalize=True).round(4).to_dict()\n",
    "\n",
    "        ## 1.2 work\n",
    "        # ever_income_upward_mobility\n",
    "        stats_dict['individual_unit']['work']['ever_income_upward_mobility'] = person_year_info['income_quantile_upward'].groupby(person_year_info['person_id']).apply(lambda x: x.max()>0).value_counts(normalize=True).round(4).to_dict() #x.max()>0判断是否存在1，事件是否发生过\n",
    "        # ever_occu_change\n",
    "        stats_dict['individual_unit']['work']['ever_occu_change'] = person_year_info['occu_change'].groupby(person_year_info['person_id']).apply(lambda x: x.max()>0).value_counts(normalize=True).round(4).to_dict()\n",
    "        # ever_industry_change\n",
    "        if dataset == 'psid':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x[p_70_start:p_70_end+1]))+len(set(x[p_00_start:p_00_end+1]))+len(set(x[p_10_start:p_10_end+1]))>3, axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "        if dataset == 'nlsy':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x[y_70_start:y_70_end+1]))+len(set(x[y_00_4_start:y_00_4_end+1]))>2, axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "        if dataset == 'nlsw':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x[w_60_start:w_60_end+1]))+len(set(x[w_90_start:w_90_end+1]))>2, axis=1).value_counts(normalize=True).round(4).to_dict()    \n",
    "        if dataset == 'nlsm':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x))>1, axis=1).value_counts(normalize=True).round(4).to_dict()     \n",
    "        #len(set(x[y_70_start:y_70_end+1]))+len(set(x[y_00_4_start:y_00_4_end+1]))\n",
    "        ## 1.3 life\n",
    "        # 定义提取life_sequence序列的函数\n",
    "        def everfun(row, colname):\n",
    "            if list(filter(None, row))==[]:\n",
    "                return 'none'\n",
    "            elif pd.DataFrame(list(filter(None, list(row))))[colname].max()>0:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        df_life = pd.DataFrame(people_dict[0]['life_sequence'])\n",
    "        # ever_married\n",
    "        stats_dict['individual_unit']['life']['ever_married'] = pd.DataFrame(list(pd.DataFrame(people_dict)['life_sequence'])).apply(lambda row: everfun(row, 'marriage_status_change'), axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "\n",
    "        stats_dict['individual_unit']['life']['ever_have_child'] = pd.DataFrame(list(pd.DataFrame(people_dict)['life_sequence'])).apply(lambda row: everfun(row, 'child_under_18'), axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "        # ever_migrated\n",
    "        stats_dict['individual_unit']['life']['ever_migrated'] = pd.DataFrame(list(pd.DataFrame(people_dict)['life_sequence'])).apply(lambda row: everfun(row, 'migration_status'), axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "\n",
    "        ### person_year_unit\n",
    "        def count_percent(x):\n",
    "            per = (x>0).value_counts(normalize=True).round(4).to_dict()\n",
    "            return per\n",
    "        ## work\n",
    "        stats_dict['person_year_unit']['work']['income_upward_mobility'] = count_percent(person_year_info['income_quantile_upward'])\n",
    "        stats_dict['person_year_unit']['work']['income_downward_mobility'] = count_percent(person_year_info['income_quantile_downward'])\n",
    "        stats_dict['person_year_unit']['work']['occu_change'] = count_percent(person_year_info['occu_change'])\n",
    "        # industry_change（特殊）\n",
    "        stats_dict['person_year_unit']['work']['industry_change'] = {\"true\":0, \"false\":0}\n",
    "        stats_dict['person_year_unit']['work']['industry_change'][\"true\"] = round((df_industry[df_industry>0].sum().sum())/(df_industry.shape[0]*df_industry.shape[1]), 4)\n",
    "        stats_dict['person_year_unit']['work']['industry_change'][\"false\"] = 1-stats_dict['person_year_unit']['work']['industry_change'][\"true\"]\n",
    "        ## life\n",
    "        if dataset == 'nlsy':\n",
    "            lfe_trans_list = ['have child(ren) under 18_to_have no child under 18',\n",
    "            'have no child under 18_to_have child(ren) under 18', 'migration', 'central_nocentral', 'nocentral_central', 'other_migration',\n",
    "            'marrital_status-single_to_couple', 'marrital_status-couple_to_single',\n",
    "            'marrital_status-single_to_single']\n",
    "            lfe_name_list = ['childbearing_yes_no','childbearing_no_yes', 'has_migration', 'central_nocentral', 'nocentral_central', 'other_migration','single_couple', 'couple_single', 'single_single']\n",
    "        else:\n",
    "            lfe_trans_list = ['have child(ren) under 18_to_have no child under 18',\n",
    "            'have no child under 18_to_have child(ren) under 18', 'migration',\n",
    "            'marrital_status-single_to_couple', 'marrital_status-couple_to_single',\n",
    "            'marrital_status-single_to_single']\n",
    "            lfe_name_list = ['childbearing_yes_no','childbearing_no_yes', 'has_migration', 'single_couple', 'couple_single', 'single_single']\n",
    "            \n",
    "        for idx, event in enumerate(lfe_trans_list):\n",
    "            stats_dict['person_year_unit']['life'][lfe_name_list[idx]] = count_percent(person_year_info[event])\n",
    "        ## income_upward_mobility_trend\n",
    "        # relative_time\n",
    "        stats_dict['person_year_unit']['income_upward_mobility_trend']['relative_time'] = person_year_info['income_quantile_upward'].groupby(person_year_info['rank']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "        # absolute_time\n",
    "        stats_dict['person_year_unit']['income_upward_mobility_trend']['absolute_time'] = person_year_info['income_quantile_upward'].groupby(person_year_info['year']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "\n",
    "        ## income_downward_mobility_trend\n",
    "        # relative_time\n",
    "        stats_dict['person_year_unit']['income_downward_mobility_trend']['relative_time'] = person_year_info['income_quantile_downward'].groupby(person_year_info['rank']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "        # absolute_time\n",
    "        stats_dict['person_year_unit']['income_downward_mobility_trend']['absolute_time'] = person_year_info['income_quantile_downward'].groupby(person_year_info['year']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "\n",
    "    \n",
    "        stats_dict_list.append(stats_dict)\n",
    "        \n",
    "    separate_dict[\"group_statistics\"] = stats_dict_list   \n",
    "    ### 输出\n",
    "    with open('D:/A李杜若/留学/科研/可视化_王懿芳学姐/CFPS/NLS/4-descriptive-stats/'+dataset+'-stats-race.json', 'w') as f:\n",
    "        json.dump(separate_dict,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### education group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_id\n",
       "1002       {'year': None, 'highest_education_level': None...\n",
       "1003       {'year': None, 'highest_education_level': None...\n",
       "2002       {'year': None, 'highest_education_level': 'hig...\n",
       "2170       {'year': None, 'highest_education_level': None...\n",
       "3001       {'year': None, 'highest_education_level': None...\n",
       "                                 ...                        \n",
       "9304001    {'year': None, 'highest_education_level': 'col...\n",
       "9305001    {'year': None, 'highest_education_level': 'hig...\n",
       "9306001    {'year': 1975, 'highest_education_level': 'col...\n",
       "9307001    {'year': None, 'highest_education_level': 'hig...\n",
       "9308002    {'year': None, 'highest_education_level': 'hig...\n",
       "Name: education, Length: 31286, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('psid_imputed.json') as json_file:\n",
    "    people_dict0 = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>first_job</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1922</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': '5'}</td>\n",
       "      <td>{'year': None, 'highest_education_level': None...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1947</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>{'year': 1967, 'income': None, 'occupation': '7'}</td>\n",
       "      <td>{'year': None, 'highest_education_level': None...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>1912</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': '7'}</td>\n",
       "      <td>{'year': None, 'highest_education_level': 'hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>1907</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': '7'}</td>\n",
       "      <td>{'year': None, 'highest_education_level': None...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>1891</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': '8'}</td>\n",
       "      <td>{'year': None, 'highest_education_level': None...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9304001</th>\n",
       "      <td>1929</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': '7'}</td>\n",
       "      <td>{'year': None, 'highest_education_level': 'col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9305001</th>\n",
       "      <td>1950</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': '7'}</td>\n",
       "      <td>{'year': None, 'highest_education_level': 'hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9306001</th>\n",
       "      <td>1953</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': '9'}</td>\n",
       "      <td>{'year': 1975, 'highest_education_level': 'col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9307001</th>\n",
       "      <td>1949</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': '7'}</td>\n",
       "      <td>{'year': None, 'highest_education_level': 'hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308002</th>\n",
       "      <td>1967</td>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>{'year': None, 'income': None, 'occupation': N...</td>\n",
       "      <td>{'year': None, 'highest_education_level': 'hig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31286 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           birth_year  gender   race  \\\n",
       "person_id                              \n",
       "1002             1922  female  white   \n",
       "1003             1947    male  white   \n",
       "2002             1912  female  white   \n",
       "2170             1907    male  white   \n",
       "3001             1891    male  white   \n",
       "...               ...     ...    ...   \n",
       "9304001          1929    male  white   \n",
       "9305001          1950    male  white   \n",
       "9306001          1953    male  white   \n",
       "9307001          1949  female  black   \n",
       "9308002          1967  female  other   \n",
       "\n",
       "                                                   first_job  \\\n",
       "person_id                                                      \n",
       "1002       {'year': None, 'income': None, 'occupation': '5'}   \n",
       "1003       {'year': 1967, 'income': None, 'occupation': '7'}   \n",
       "2002       {'year': None, 'income': None, 'occupation': '7'}   \n",
       "2170       {'year': None, 'income': None, 'occupation': '7'}   \n",
       "3001       {'year': None, 'income': None, 'occupation': '8'}   \n",
       "...                                                      ...   \n",
       "9304001    {'year': None, 'income': None, 'occupation': '7'}   \n",
       "9305001    {'year': None, 'income': None, 'occupation': '7'}   \n",
       "9306001    {'year': None, 'income': None, 'occupation': '9'}   \n",
       "9307001    {'year': None, 'income': None, 'occupation': '7'}   \n",
       "9308002    {'year': None, 'income': None, 'occupation': N...   \n",
       "\n",
       "                                                   education  \n",
       "person_id                                                     \n",
       "1002       {'year': None, 'highest_education_level': None...  \n",
       "1003       {'year': None, 'highest_education_level': None...  \n",
       "2002       {'year': None, 'highest_education_level': 'hig...  \n",
       "2170       {'year': None, 'highest_education_level': None...  \n",
       "3001       {'year': None, 'highest_education_level': None...  \n",
       "...                                                      ...  \n",
       "9304001    {'year': None, 'highest_education_level': 'col...  \n",
       "9305001    {'year': None, 'highest_education_level': 'hig...  \n",
       "9306001    {'year': 1975, 'highest_education_level': 'col...  \n",
       "9307001    {'year': None, 'highest_education_level': 'hig...  \n",
       "9308002    {'year': None, 'highest_education_level': 'hig...  \n",
       "\n",
       "[31286 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd1 = pd.DataFrame(list(pd.DataFrame(people_dict0)['basic_info'])).set_index(pd.Index(pd.DataFrame(people_dict0)['person_id'])).dropna()\n",
    "dd = pd.DataFrame(list(dd1['education'])).set_index(dd1.index)\n",
    "#dd[dd['education']['highest_education_level'] == 'high-school'].index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_dictionary(dataset):\n",
    "    with open(dataset + '_imputed.json') as json_file:\n",
    "        people_dict0 = json.load(json_file)\n",
    "    person_year_info0 =pd.read_csv(dataset + '-person-year-combine.csv').set_index('person_id', drop=False)\n",
    "    person_year_info0.index = person_year_info0.index.astype('string')\n",
    "    person_year_info0.index.name = None\n",
    "    if dataset == 'nlsy':\n",
    "        person_year_info0['migration']= person_year_info0[['central_nocentral', 'nocentral_central', 'other_migration']].sum(axis=1)\n",
    "        person_year_info0[person_year_info0<0]=-1\n",
    "\n",
    "    df_people_indu_level0 = pd.read_csv(dataset + '_industry_info.csv', index_col='Unnamed: 0')\n",
    "    df_people_indu_level0.index = df_people_indu_level0.index.astype('string')\n",
    "    df_industry0 = pd.read_csv(dataset + '_industry_change_abs.csv', index_col='Unnamed: 0')\n",
    "    df_industry0.index = df_industry0.index.astype('string')\n",
    "    ### 0.准备\n",
    "    separate_dict = {\n",
    "        \"dataset_size\":5000,\n",
    "        \"group_statistics\":[] \n",
    "    }   \n",
    "    ## 储存edu分别的stats_dict\n",
    "    stats_dict_list = []\n",
    "    edu_list = ['college', 'high-school', 'high-school-noncompletion']\n",
    "    ## 储存person_id\n",
    "    dd1 = pd.DataFrame(list(pd.DataFrame(people_dict0)['basic_info'])).set_index(pd.Index(pd.DataFrame(people_dict0)['person_id'])).dropna()\n",
    "    dd = pd.DataFrame(list(dd1['education'])).set_index(dd1.index)\n",
    "\n",
    "    # if dataset == \"nlsw\":\n",
    "    #     w_id_list = list(dd.index)\n",
    "    #     b_id_list = []\n",
    "    # elif dataset == 'nlsm':\n",
    "    #     f_id_list = []\n",
    "    #     m_id_list = list(dd.index)\n",
    "    # else:\n",
    "    edu_id_lists = []\n",
    "    for edu in edu_list:\n",
    "        edu_id_lists.append(list(dd[dd['highest_education_level'] == edu].index))\n",
    "        \n",
    "    ## 获取dataset_size\n",
    "    total_num = len(people_dict0)\n",
    "    separate_dict['dataset_size'] = total_num\n",
    "    \n",
    "    for e_idx, edu in enumerate(edu_list):\n",
    "        # if (dataset == 'nlsw' and race == 'male') or (dataset == 'nlsm' and race == 'female'):\n",
    "        #     continue\n",
    "\n",
    "        # 每次都要重新创建新的dict，不然会连为一体\n",
    "        stats_dict = {\n",
    "        \"individual_unit\": {\n",
    "            \"demographic\": {\n",
    "                \"gender\": {\"male\": 0.45, \"female\": 0.5, \"others\": 0.05},\n",
    "                \"race\": {\"white\": 0.6, \"black\": 0.35, \"others\": 0.05}, \n",
    "                \"birth_year\": {\"70\": 0.45, \"80\": 0.35, \"90\": 0.2},\n",
    "                \"education_level\": {\"high-school-noncompletion\": 0.5, \"high-school\": 0.3, \"college\": 0.15, \"none\": 0.05}, \n",
    "            },\n",
    "            \"work\": {  # 这个人至少发生一次如下event，就计数为1。统计label为1的人数占总人数的百分比\n",
    "                \"ever_income_upward_mobility\": 0.01,\n",
    "                \"ever_occu_change\": 0.002,\n",
    "                \"ever_industry_change\": 0.003\n",
    "            },\n",
    "            \"life\": {\n",
    "                \"ever_married\": 0.6,\n",
    "                \"ever_have_child\": 0.4,\n",
    "                \"ever_migrated\": 0.2\n",
    "            }\n",
    "        },\n",
    "        \"person_year_unit\": {\n",
    "            \"work\": {\n",
    "                \"income_upward_mobility\": 0.001,\n",
    "                \"income_downward_mobility\": 0.001,\n",
    "                \"occu_change\": 0.002,\n",
    "                \"industry_change\": 0.003\n",
    "            },\n",
    "            \"life\": {\n",
    "                # 1. transfer events\n",
    "                \"single_couple\": 0.02,\n",
    "                \"couple_single\": 0.01,\n",
    "                \"childbearing_no_yes\": 0.01,\n",
    "            },\n",
    "            \"income_upward_mobility_trend\": {\n",
    "                \"relative_time\": {\n",
    "                    \"1\": 0.02, # 含义：工作第1年，相比于工作第0年，发生upward mobility的人占所有人数的百分之多少\n",
    "                    \"2\": 0.04,\n",
    "                    \n",
    "                },\n",
    "                \"absolute_time\": {\n",
    "                    \"1966\": 0.05, # 含义：1966年发生upward mobility的人占所有人数的百分之多少\n",
    "                    \"1967\": 0.06,\n",
    "                    \n",
    "                }\n",
    "            }, \n",
    "            \"income_downward_mobility_trend\": {\n",
    "                \"relative_time\": {\n",
    "                    \"1\": 0.02, \n",
    "                    \"2\": 0.04,\n",
    "                    \n",
    "                },\n",
    "                \"absolute_time\": {\n",
    "                    \"1966\": 0.05, \n",
    "                    \"1967\": 0.06,\n",
    "                    \n",
    "                }\n",
    "            }, \n",
    "        }\n",
    "    }\n",
    "        edu_id_list = edu_id_lists[e_idx]\n",
    "        stats_dict['group_name']=edu\n",
    "        \n",
    "        ### 1.individual_unit\n",
    "        # 获取指定性别的 people_dict\n",
    "        people_dict = [person for person in people_dict0 if person['person_id'] in edu_id_list]\n",
    "        df_demo = pd.DataFrame(list(pd.DataFrame(people_dict)['basic_info']))\n",
    "        # 获取指定性别的 person_year_info\n",
    "        person_year_info = person_year_info0.loc[person_year_info0.index.intersection(edu_id_list)]\n",
    "        # 获取指定性别的industry info\n",
    "        df_people_indu_level = df_people_indu_level0.loc[df_people_indu_level0.index.intersection(edu_id_list)]\n",
    "        df_industry = df_industry0.loc[df_industry0.index.intersection(edu_id_list)]\n",
    "        \n",
    "        # rank是为了绝对对齐\n",
    "        cumm = 0\n",
    "        person_year_info['rank']=0\n",
    "        for idx, length  in enumerate(person_year_info.groupby('person_id').size()):\n",
    "            person_year_info['rank'][cumm:cumm+length]=range(length)\n",
    "            cumm = cumm+length\n",
    "            \n",
    "        ## 1.1 demographic\n",
    "        # gender\n",
    "        if dataset == 'nlsw':\n",
    "            stats_dict['individual_unit']['demographic']['gender']={\"male\": 0, \"female\": 1, \"others\": 0}\n",
    "        elif dataset == 'nlsm':\n",
    "            stats_dict['individual_unit']['demographic']['gender']={\"male\": 1, \"female\": 0, \"others\": 0}\n",
    "        else:\n",
    "            stats_dict['individual_unit']['demographic']['gender'] = df_demo['gender'].fillna('none').value_counts(normalize=True).round(4).to_dict()\n",
    "        # race\n",
    "        stats_dict['individual_unit']['demographic']['race'] = df_demo['race'].fillna('none').value_counts(normalize=True).round(4).to_dict()\n",
    "        # birth_year\n",
    "        ## 计算年代范围\n",
    "        start_bir = 10*int((df_demo['birth_year'][df_demo['birth_year']>1200].describe()['min']-1800)/10)+1800\n",
    "        end_bir = 10*ceil((df_demo['birth_year'].describe()['max']-1900)/10)+1900\n",
    "        if dataset == 'nlsy':\n",
    "            stats_dict['individual_unit']['demographic']['birth_year'] = pd.cut(df_demo['birth_year'].fillna(\"none\"), [i for i in range(start_bir,end_bir+10,10)], right=False,labels=[f'{i}s' for i in range(start_bir,end_bir,10)]).value_counts(normalize=True).round(4).to_dict()\n",
    "        else:\n",
    "            stats_dict['individual_unit']['demographic']['birth_year'] = pd.cut(df_demo['birth_year'], [i for i in range(start_bir,end_bir+10,10)], right=False,labels=[f'{i}s' for i in range(start_bir,end_bir,10)]).cat.add_categories([\"none\"]).fillna(\"none\").value_counts(normalize=True).round(4).to_dict()\n",
    "        #education_level\n",
    "        stats_dict['individual_unit']['demographic']['education_level'] = pd.DataFrame(list(df_demo['education'].dropna()))['highest_education_level'].fillna('none').value_counts(normalize=True).round(4).to_dict()\n",
    "\n",
    "        ## 1.2 work\n",
    "        # ever_income_upward_mobility\n",
    "        stats_dict['individual_unit']['work']['ever_income_upward_mobility'] = person_year_info['income_quantile_upward'].groupby(person_year_info['person_id']).apply(lambda x: x.max()>0).value_counts(normalize=True).round(4).to_dict() #x.max()>0判断是否存在1，事件是否发生过\n",
    "        # ever_occu_change\n",
    "        stats_dict['individual_unit']['work']['ever_occu_change'] = person_year_info['occu_change'].groupby(person_year_info['person_id']).apply(lambda x: x.max()>0).value_counts(normalize=True).round(4).to_dict()\n",
    "        # ever_industry_change\n",
    "        if dataset == 'psid':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x[p_70_start:p_70_end+1]))+len(set(x[p_00_start:p_00_end+1]))+len(set(x[p_10_start:p_10_end+1]))>3, axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "        if dataset == 'nlsy':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x[y_70_start:y_70_end+1]))+len(set(x[y_00_4_start:y_00_4_end+1]))>2, axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "        if dataset == 'nlsw':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x[w_60_start:w_60_end+1]))+len(set(x[w_90_start:w_90_end+1]))>2, axis=1).value_counts(normalize=True).round(4).to_dict()    \n",
    "        if dataset == 'nlsm':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x))>1, axis=1).value_counts(normalize=True).round(4).to_dict()     \n",
    "        #len(set(x[y_70_start:y_70_end+1]))+len(set(x[y_00_4_start:y_00_4_end+1]))\n",
    "        ## 1.3 life\n",
    "        # 定义提取life_sequence序列的函数\n",
    "        def everfun(row, colname):\n",
    "            if list(filter(None, row))==[]:\n",
    "                return 'none'\n",
    "            elif pd.DataFrame(list(filter(None, list(row))))[colname].max()>0:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        df_life = pd.DataFrame(people_dict[0]['life_sequence'])\n",
    "        # ever_married\n",
    "        stats_dict['individual_unit']['life']['ever_married'] = pd.DataFrame(list(pd.DataFrame(people_dict)['life_sequence'])).apply(lambda row: everfun(row, 'marriage_status_change'), axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "\n",
    "        stats_dict['individual_unit']['life']['ever_have_child'] = pd.DataFrame(list(pd.DataFrame(people_dict)['life_sequence'])).apply(lambda row: everfun(row, 'child_under_18'), axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "        # ever_migrated\n",
    "        stats_dict['individual_unit']['life']['ever_migrated'] = pd.DataFrame(list(pd.DataFrame(people_dict)['life_sequence'])).apply(lambda row: everfun(row, 'migration_status'), axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "\n",
    "        ### person_year_unit\n",
    "        def count_percent(x):\n",
    "            per = (x>0).value_counts(normalize=True).round(4).to_dict()\n",
    "            return per\n",
    "        ## work\n",
    "        stats_dict['person_year_unit']['work']['income_upward_mobility'] = count_percent(person_year_info['income_quantile_upward'])\n",
    "        stats_dict['person_year_unit']['work']['income_downward_mobility'] = count_percent(person_year_info['income_quantile_downward'])\n",
    "        stats_dict['person_year_unit']['work']['occu_change'] = count_percent(person_year_info['occu_change'])\n",
    "        # industry_change（特殊）\n",
    "        stats_dict['person_year_unit']['work']['industry_change'] = {\"true\":0, \"false\":0}\n",
    "        stats_dict['person_year_unit']['work']['industry_change'][\"true\"] = round((df_industry[df_industry>0].sum().sum())/(df_industry.shape[0]*df_industry.shape[1]), 4)\n",
    "        stats_dict['person_year_unit']['work']['industry_change'][\"false\"] = 1-stats_dict['person_year_unit']['work']['industry_change'][\"true\"]\n",
    "        ## life\n",
    "        if dataset == 'nlsy':\n",
    "            lfe_trans_list = ['have child(ren) under 18_to_have no child under 18',\n",
    "            'have no child under 18_to_have child(ren) under 18', 'migration', 'central_nocentral', 'nocentral_central', 'other_migration',\n",
    "            'marrital_status-single_to_couple', 'marrital_status-couple_to_single',\n",
    "            'marrital_status-single_to_single']\n",
    "            lfe_name_list = ['childbearing_yes_no','childbearing_no_yes', 'has_migration', 'central_nocentral', 'nocentral_central', 'other_migration','single_couple', 'couple_single', 'single_single']\n",
    "        else:\n",
    "            lfe_trans_list = ['have child(ren) under 18_to_have no child under 18',\n",
    "            'have no child under 18_to_have child(ren) under 18', 'migration',\n",
    "            'marrital_status-single_to_couple', 'marrital_status-couple_to_single',\n",
    "            'marrital_status-single_to_single']\n",
    "            lfe_name_list = ['childbearing_yes_no','childbearing_no_yes', 'has_migration', 'single_couple', 'couple_single', 'single_single']\n",
    "            \n",
    "        for idx, event in enumerate(lfe_trans_list):\n",
    "            stats_dict['person_year_unit']['life'][lfe_name_list[idx]] = count_percent(person_year_info[event])\n",
    "        ## income_upward_mobility_trend\n",
    "        # relative_time\n",
    "        stats_dict['person_year_unit']['income_upward_mobility_trend']['relative_time'] = person_year_info['income_quantile_upward'].groupby(person_year_info['rank']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "        # absolute_time\n",
    "        stats_dict['person_year_unit']['income_upward_mobility_trend']['absolute_time'] = person_year_info['income_quantile_upward'].groupby(person_year_info['year']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "\n",
    "        ## income_downward_mobility_trend\n",
    "        # relative_time\n",
    "        stats_dict['person_year_unit']['income_downward_mobility_trend']['relative_time'] = person_year_info['income_quantile_downward'].groupby(person_year_info['rank']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "        # absolute_time\n",
    "        stats_dict['person_year_unit']['income_downward_mobility_trend']['absolute_time'] = person_year_info['income_quantile_downward'].groupby(person_year_info['year']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "\n",
    "    \n",
    "        stats_dict_list.append(stats_dict)\n",
    "        \n",
    "    separate_dict[\"group_statistics\"] = stats_dict_list   \n",
    "    ### 输出\n",
    "    with open('D:/A李杜若/留学/科研/可视化_王懿芳学姐/CFPS/NLS/4-descriptive-stats/'+dataset+'-stats-edu.json', 'w') as f:\n",
    "        json.dump(separate_dict,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### birth_year_range group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_dictionary(dataset):\n",
    "    with open(dataset + '_imputed.json') as json_file:\n",
    "        people_dict0 = json.load(json_file)\n",
    "    person_year_info0 =pd.read_csv(dataset + '-person-year-combine.csv').set_index('person_id', drop=False)\n",
    "    person_year_info0.index = person_year_info0.index.astype('string')\n",
    "    person_year_info0.index.name = None\n",
    "    if dataset == 'nlsy':\n",
    "        person_year_info0['migration']= person_year_info0[['central_nocentral', 'nocentral_central', 'other_migration']].sum(axis=1)\n",
    "        person_year_info0[person_year_info0<0]=-1\n",
    "\n",
    "    df_people_indu_level0 = pd.read_csv(dataset + '_industry_info.csv', index_col='Unnamed: 0')\n",
    "    df_people_indu_level0.index = df_people_indu_level0.index.astype('string')\n",
    "    df_industry0 = pd.read_csv(dataset + '_industry_change_abs.csv', index_col='Unnamed: 0')\n",
    "    df_industry0.index = df_industry0.index.astype('string')\n",
    "    ### 0.准备\n",
    "    separate_dict = {\n",
    "        \"dataset_size\":5000,\n",
    "        \"group_statistics\":[] \n",
    "    }   \n",
    "    ## 储存'white','black','other'分别的stats_dict\n",
    "    stats_dict_list = []\n",
    "    ## 储存person_id\n",
    "    dd = pd.DataFrame(list(pd.DataFrame(people_dict0)['basic_info'])).set_index(pd.Index(pd.DataFrame(people_dict0)['person_id']))\n",
    "    start_bir = 1900\n",
    "    end_bir = 10*ceil((dd['birth_year'].describe()['max']-1900)/10)+1900\n",
    "    dd['birth_year_range'] = pd.cut(dd['birth_year'], [i for i in range(start_bir,end_bir+10,10)], right=False,labels=[f'{i}s' for i in range(start_bir,end_bir,10)]).cat.add_categories([\"none\"]).fillna(\"none\")\n",
    "    year_range_list = list(pd.Categorical(dd['birth_year_range']).categories)[:-1]\n",
    "    \n",
    "    \n",
    "    # if dataset == \"nlsw\":\n",
    "    #     w_id_list = list(dd.index)\n",
    "    #     b_id_list = []\n",
    "    # elif dataset == 'nlsm':\n",
    "    #     f_id_list = []\n",
    "    #     m_id_list = list(dd.index)\n",
    "    # else:\n",
    "    yr_id_lists = []\n",
    "    for year_range in year_range_list:\n",
    "        yr_id_lists.append(list(dd[dd['birth_year_range'] == year_range].index))\n",
    "        \n",
    "    ## 获取dataset_size\n",
    "    total_num = len(people_dict0)\n",
    "    separate_dict['dataset_size'] = total_num\n",
    "    \n",
    "    for y_idx, year_range in enumerate(year_range_list):\n",
    "        # if (dataset == 'nlsw' and year_range == 'male') or (dataset == 'nlsm' and year_range == 'female'):\n",
    "        #     continue\n",
    "\n",
    "        # 每次都要重新创建新的dict，不然会连为一体\n",
    "        stats_dict = {\n",
    "        \"individual_unit\": {\n",
    "            \"demographic\": {\n",
    "                \"gender\": {\"male\": 0.45, \"female\": 0.5, \"others\": 0.05},\n",
    "                \"year_range\": {\"white\": 0.6, \"black\": 0.35, \"others\": 0.05}, \n",
    "                \"birth_year\": {\"70\": 0.45, \"80\": 0.35, \"90\": 0.2},\n",
    "                \"education_level\": {\"high-school-noncompletion\": 0.5, \"high-school\": 0.3, \"college\": 0.15, \"none\": 0.05}, \n",
    "            },\n",
    "            \"work\": {  # 这个人至少发生一次如下event，就计数为1。统计label为1的人数占总人数的百分比\n",
    "                \"ever_income_upward_mobility\": 0.01,\n",
    "                \"ever_occu_change\": 0.002,\n",
    "                \"ever_industry_change\": 0.003\n",
    "            },\n",
    "            \"life\": {\n",
    "                \"ever_married\": 0.6,\n",
    "                \"ever_have_child\": 0.4,\n",
    "                \"ever_migrated\": 0.2\n",
    "            }\n",
    "        },\n",
    "        \"person_year_unit\": {\n",
    "            \"work\": {\n",
    "                \"income_upward_mobility\": 0.001,\n",
    "                \"income_downward_mobility\": 0.001,\n",
    "                \"occu_change\": 0.002,\n",
    "                \"industry_change\": 0.003\n",
    "            },\n",
    "            \"life\": {\n",
    "                # 1. transfer events\n",
    "                \"single_couple\": 0.02,\n",
    "                \"couple_single\": 0.01,\n",
    "                \"childbearing_no_yes\": 0.01,\n",
    "            },\n",
    "            \"income_upward_mobility_trend\": {\n",
    "                \"relative_time\": {\n",
    "                    \"1\": 0.02, # 含义：工作第1年，相比于工作第0年，发生upward mobility的人占所有人数的百分之多少\n",
    "                    \"2\": 0.04,\n",
    "                    \n",
    "                },\n",
    "                \"absolute_time\": {\n",
    "                    \"1966\": 0.05, # 含义：1966年发生upward mobility的人占所有人数的百分之多少\n",
    "                    \"1967\": 0.06,\n",
    "                    \n",
    "                }\n",
    "            }, \n",
    "            \"income_downward_mobility_trend\": {\n",
    "                \"relative_time\": {\n",
    "                    \"1\": 0.02, \n",
    "                    \"2\": 0.04,\n",
    "                    \n",
    "                },\n",
    "                \"absolute_time\": {\n",
    "                    \"1966\": 0.05, \n",
    "                    \"1967\": 0.06,\n",
    "                    \n",
    "                }\n",
    "            }, \n",
    "        }\n",
    "    }\n",
    "        yr_id_list = yr_id_lists[y_idx]\n",
    "        stats_dict['group_name']=year_range\n",
    "        \n",
    "        ### 1.individual_unit\n",
    "        # 获取指定年份的 people_dict\n",
    "        people_dict = [person for person in people_dict0 if person['person_id'] in yr_id_list]\n",
    "        df_demo = pd.DataFrame(list(pd.DataFrame(people_dict)['basic_info']))\n",
    "        # 获取指定年份的 person_year_info\n",
    "        person_year_info = person_year_info0.loc[person_year_info0.index.intersection(yr_id_list)]\n",
    "        # 获取指定年份的industry info\n",
    "        df_people_indu_level = df_people_indu_level0.loc[df_people_indu_level0.index.intersection(yr_id_list)]\n",
    "        df_industry = df_industry0.loc[df_industry0.index.intersection(yr_id_list)]\n",
    "        \n",
    "        # rank是为了绝对对齐\n",
    "        cumm = 0\n",
    "        person_year_info['rank']=0\n",
    "        for idx, length  in enumerate(person_year_info.groupby('person_id').size()):\n",
    "            person_year_info['rank'][cumm:cumm+length]=range(length)\n",
    "            cumm = cumm+length\n",
    "            \n",
    "        ## 1.1 demographic\n",
    "        # gender\n",
    "        if dataset == 'nlsw':\n",
    "            stats_dict['individual_unit']['demographic']['gender']={\"male\": 0, \"female\": 1, \"others\": 0}\n",
    "        elif dataset == 'nlsm':\n",
    "            stats_dict['individual_unit']['demographic']['gender']={\"male\": 1, \"female\": 0, \"others\": 0}\n",
    "        else:\n",
    "            stats_dict['individual_unit']['demographic']['gender'] = df_demo['gender'].fillna('none').value_counts(normalize=True).round(4).to_dict()\n",
    "        # race\n",
    "        stats_dict['individual_unit']['demographic']['race'] = df_demo['race'].fillna('none').value_counts(normalize=True).round(4).to_dict()\n",
    "        # birth_year\n",
    "        ## 计算年代范围\n",
    "        start_bir = 10*int((df_demo['birth_year'][df_demo['birth_year']>1200].describe()['min']-1800)/10)+1800\n",
    "        end_bir = 10*ceil((df_demo['birth_year'].describe()['max']-1900)/10)+1900\n",
    "        if dataset == 'nlsy':\n",
    "            stats_dict['individual_unit']['demographic']['birth_year'] = pd.cut(df_demo['birth_year'].fillna(\"none\"), [i for i in range(start_bir,end_bir+10,10)], right=False,labels=[f'{i}s' for i in range(start_bir,end_bir,10)]).value_counts(normalize=True).round(4).to_dict()\n",
    "        else:\n",
    "            stats_dict['individual_unit']['demographic']['birth_year'] = pd.cut(df_demo['birth_year'], [i for i in range(start_bir,end_bir+10,10)], right=False,labels=[f'{i}s' for i in range(start_bir,end_bir,10)]).cat.add_categories([\"none\"]).fillna(\"none\").value_counts(normalize=True).round(4).to_dict()\n",
    "        #education_level\n",
    "        stats_dict['individual_unit']['demographic']['education_level'] = pd.DataFrame(list(df_demo['education'].dropna()))['highest_education_level'].fillna('none').value_counts(normalize=True).round(4).to_dict()\n",
    "\n",
    "        ## 1.2 work\n",
    "        # ever_income_upward_mobility\n",
    "        stats_dict['individual_unit']['work']['ever_income_upward_mobility'] = person_year_info['income_quantile_upward'].groupby(person_year_info['person_id']).apply(lambda x: x.max()>0).value_counts(normalize=True).round(4).to_dict() #x.max()>0判断是否存在1，事件是否发生过\n",
    "        # ever_occu_change\n",
    "        stats_dict['individual_unit']['work']['ever_occu_change'] = person_year_info['occu_change'].groupby(person_year_info['person_id']).apply(lambda x: x.max()>0).value_counts(normalize=True).round(4).to_dict()\n",
    "        # ever_industry_change\n",
    "        if dataset == 'psid':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x[p_70_start:p_70_end+1]))+len(set(x[p_00_start:p_00_end+1]))+len(set(x[p_10_start:p_10_end+1]))>3, axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "        if dataset == 'nlsy':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x[y_70_start:y_70_end+1]))+len(set(x[y_00_4_start:y_00_4_end+1]))>2, axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "        if dataset == 'nlsw':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x[w_60_start:w_60_end+1]))+len(set(x[w_90_start:w_90_end+1]))>2, axis=1).value_counts(normalize=True).round(4).to_dict()    \n",
    "        if dataset == 'nlsm':\n",
    "            stats_dict['individual_unit']['work']['ever_industry_change'] = df_people_indu_level.apply(lambda x: len(set(x))>1, axis=1).value_counts(normalize=True).round(4).to_dict()     \n",
    "        #len(set(x[y_70_start:y_70_end+1]))+len(set(x[y_00_4_start:y_00_4_end+1]))\n",
    "        ## 1.3 life\n",
    "        # 定义提取life_sequence序列的函数\n",
    "        def everfun(row, colname):\n",
    "            if list(filter(None, row))==[]:\n",
    "                return 'none'\n",
    "            elif pd.DataFrame(list(filter(None, list(row))))[colname].max()>0:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        df_life = pd.DataFrame(people_dict[0]['life_sequence'])\n",
    "        # ever_married\n",
    "        stats_dict['individual_unit']['life']['ever_married'] = pd.DataFrame(list(pd.DataFrame(people_dict)['life_sequence'])).apply(lambda row: everfun(row, 'marriage_status_change'), axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "\n",
    "        stats_dict['individual_unit']['life']['ever_have_child'] = pd.DataFrame(list(pd.DataFrame(people_dict)['life_sequence'])).apply(lambda row: everfun(row, 'child_under_18'), axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "        # ever_migrated\n",
    "        stats_dict['individual_unit']['life']['ever_migrated'] = pd.DataFrame(list(pd.DataFrame(people_dict)['life_sequence'])).apply(lambda row: everfun(row, 'migration_status'), axis=1).value_counts(normalize=True).round(4).to_dict()\n",
    "\n",
    "        ### person_year_unit\n",
    "        def count_percent(x):\n",
    "            per = (x>0).value_counts(normalize=True).round(4).to_dict()\n",
    "            return per\n",
    "        ## work\n",
    "        stats_dict['person_year_unit']['work']['income_upward_mobility'] = count_percent(person_year_info['income_quantile_upward'])\n",
    "        stats_dict['person_year_unit']['work']['income_downward_mobility'] = count_percent(person_year_info['income_quantile_downward'])\n",
    "        stats_dict['person_year_unit']['work']['occu_change'] = count_percent(person_year_info['occu_change'])\n",
    "        # industry_change（特殊）\n",
    "        stats_dict['person_year_unit']['work']['industry_change'] = {\"true\":0, \"false\":0}\n",
    "        stats_dict['person_year_unit']['work']['industry_change'][\"true\"] = round((df_industry[df_industry>0].sum().sum())/(df_industry.shape[0]*df_industry.shape[1]), 4)\n",
    "        stats_dict['person_year_unit']['work']['industry_change'][\"false\"] = 1-stats_dict['person_year_unit']['work']['industry_change'][\"true\"]\n",
    "        ## life\n",
    "        if dataset == 'nlsy':\n",
    "            lfe_trans_list = ['have child(ren) under 18_to_have no child under 18',\n",
    "            'have no child under 18_to_have child(ren) under 18', 'migration', 'central_nocentral', 'nocentral_central', 'other_migration',\n",
    "            'marrital_status-single_to_couple', 'marrital_status-couple_to_single',\n",
    "            'marrital_status-single_to_single']\n",
    "            lfe_name_list = ['childbearing_yes_no','childbearing_no_yes', 'has_migration', 'central_nocentral', 'nocentral_central', 'other_migration','single_couple', 'couple_single', 'single_single']\n",
    "        else:\n",
    "            lfe_trans_list = ['have child(ren) under 18_to_have no child under 18',\n",
    "            'have no child under 18_to_have child(ren) under 18', 'migration',\n",
    "            'marrital_status-single_to_couple', 'marrital_status-couple_to_single',\n",
    "            'marrital_status-single_to_single']\n",
    "            lfe_name_list = ['childbearing_yes_no','childbearing_no_yes', 'has_migration', 'single_couple', 'couple_single', 'single_single']\n",
    "            \n",
    "        for idx, event in enumerate(lfe_trans_list):\n",
    "            stats_dict['person_year_unit']['life'][lfe_name_list[idx]] = count_percent(person_year_info[event])\n",
    "        ## income_upward_mobility_trend\n",
    "        # relative_time\n",
    "        stats_dict['person_year_unit']['income_upward_mobility_trend']['relative_time'] = person_year_info['income_quantile_upward'].groupby(person_year_info['rank']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "        # absolute_time\n",
    "        stats_dict['person_year_unit']['income_upward_mobility_trend']['absolute_time'] = person_year_info['income_quantile_upward'].groupby(person_year_info['year']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "\n",
    "        ## income_downward_mobility_trend\n",
    "        # relative_time\n",
    "        stats_dict['person_year_unit']['income_downward_mobility_trend']['relative_time'] = person_year_info['income_quantile_downward'].groupby(person_year_info['rank']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "        # absolute_time\n",
    "        stats_dict['person_year_unit']['income_downward_mobility_trend']['absolute_time'] = person_year_info['income_quantile_downward'].groupby(person_year_info['year']).apply(lambda x:count_percent(x)).unstack().dropna().to_dict(orient ='index')\n",
    "\n",
    "    \n",
    "        stats_dict_list.append(stats_dict)\n",
    "        \n",
    "    separate_dict[\"group_statistics\"] = stats_dict_list   \n",
    "    ### 输出\n",
    "    with open('D:/A李杜若/留学/科研/可视化_王懿芳学姐/CFPS/NLS/4-descriptive-stats/'+dataset+'-stats-year_range.json', 'w') as f:\n",
    "        json.dump(separate_dict,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dictionary('nlsy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\A李杜若\\留学\\科研\\可视化_王懿芳学姐\\CFPS\\NLS\\4-descriptive-stats\\nlsw-stats1.json\", 'w') as f:\n",
    "    json.dump(stats_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## income_downward_mobility_trend\n",
    "# relative_time\n",
    "def count_percent(x):\n",
    "    per = 1-(x>0).value_counts(normalize=True)[False]\n",
    "    return per\n",
    "stats_dict['person_year_unit']['income_downward_mobility_trend']['relative_time'] = pd.Series.to_dict(person_year_info['income_quantile_downward'].groupby(person_year_info['rank']).apply(lambda x:count_percent(x)))\n",
    "# absolute_time\n",
    "stats_dict['person_year_unit']['income_downward_mobility_trend']['absolute_time'] = pd.Series.to_dict(person_year_info['income_quantile_downward'].groupby(person_year_info['year']).apply(lambda x:count_percent(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\A李杜若\\留学\\科研\\可视化_王懿芳学姐\\CFPS\\NLS\\4-descriptive-stats\\psid-stats.json\", 'w') as f:\n",
    "    json.dump(stats_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comb_mar_list = [i for i in list(person_year_info.columns) if i.startswith('marrital_status')]\n",
    "# stats_dict['individual_unit']['life']['ever_married'] = person_year_info[comb_mar_list].sum(axis=1).groupby(person_year_info['person_id']).apply(lambda x: x.max()>0).value_counts(normalize=True).to_dict()\n",
    "# ever_have_child\n",
    "# Method 1: person-year, childbearing status change\n",
    "# comb_chb_list =  [i for i in list(person_year_info.columns) if i.endswith('under 18')]\n",
    "# person_year_info[comb_chb_list].sum(axis=1).groupby(person_year_info['person_id']).apply(lambda x: x.max()>0).value_counts(normalize=True).to_dict() \n",
    "# {False: 0.557969583251037, True: 0.44203041674896304} 这样没有包括career sequence以前的event\n",
    "# Method 2: people_dict, child_under_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'ever_married': {True: 0.684376851668971,\n",
    "False: 0.31562314833102906},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_bir = 10*int((df_demo['birth_year'].describe()['min']-1900)/10)+1900\n",
    "end_bir = 10*ceil((df_demo['birth_year'].describe()['max']-1900)/10)+1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1940s': 0.6018608257414227,\n",
       " '1950s': 0.3936809459197519,\n",
       " 'none': 0.004458228338825354}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(df_demo['birth_year'], [i for i in range(start_bir,end_bir+10,10)], right=False,labels=[f'{i}s' for i in range(start_bir,end_bir,10)]).cat.add_categories(\"none\").fillna(\"none\").value_counts(normalize=True).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义根据name返回level_event_n的函数\n",
    "def get_lfe_key(map, target_lfe_name):\n",
    "    lfe_n_list = []\n",
    "    for name in target_lfe_name:\n",
    "        key = list(map.keys())[list(map.values()).index(name)]\n",
    "        lfe_n_list.append(key)\n",
    "    return lfe_n_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### person-year event 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义event函数 input：atrribute； output：由event名称列组成的list + life_event_map\n",
    "person_year_info = pd.read_csv('nlsw-person-year-2.csv')\n",
    "person_year_info0 = pd.read_csv('nlsw-person-year.csv')\n",
    "stable_attr = ['occu_change', 'industry_change', 'income_quantile_upward', 'income_quantile_downward']\n",
    "def event_creator(stable_attr, marriage_attr, residence_attr):\n",
    "    total_event_list = []\n",
    "    mar_event_list = []\n",
    "    res_event_list = []\n",
    "    \n",
    "    mar_n, res_n = len(marriage_attr), len(residence_attr)\n",
    "    for i in range(mar_n-1):\n",
    "        for j in range(i+1, mar_n):\n",
    "            mar_event_list = mar_event_list+[\n",
    "                marriage_attr[i]+'_to_'+marriage_attr[j],\n",
    "                marriage_attr[j]+'_to_'+marriage_attr[i]]\n",
    "            \n",
    "    \n",
    "    \n",
    "    for i in range(res_n-1):\n",
    "        for j in range(i+1, res_n):\n",
    "            res_event_list = res_event_list+[\n",
    "                residence_attr[i]+'_to_'+residence_attr[j],\n",
    "                residence_attr[j]+'_to_'+residence_attr[i]] \n",
    "    \n",
    "    life_event_list = mar_event_list+[\"have child(ren) under 18_to_have no child under 18\", \"have no child under 18_to_have child(ren) under 18\"]+res_event_list\n",
    "              \n",
    "    life_event_n_list = [f'life_event_{i+1}' for i in range(len(life_event_list))]\n",
    "    # create life event map\n",
    "    life_event_map = dict(zip(life_event_n_list, life_event_list))\n",
    "    # create event name list\n",
    "    total_event_list = stable_attr + life_event_n_list\n",
    "    \n",
    "    return total_event_list, life_event_n_list, life_event_map, mar_event_list, res_event_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlsw\n",
    "person_year_info = pd.read_csv('nlsw-person-year-2.csv')\n",
    "person_year_info0 = pd.read_csv('nlsw-person-year.csv')\n",
    "stable_attr = ['occu_change', 'industry_change', 'income_quantile_upward', 'income_quantile_downward']\n",
    "marriage_attr_nlsw = [\n",
    "\t   'married spouse present',\n",
    "       'married spouse absent',\n",
    "       'widowed',\n",
    "       'divorced',\n",
    "       'separate',\n",
    "       'never married',\n",
    "       'spouse absent, reason unknown']\n",
    "residence_attr_nlsw = [\n",
    "    'non-south',\n",
    "    'south']\n",
    "total_event_list, life_event_n_list, life_event_map, mar_event_list, res_event_list = event_creator(stable_attr, marriage_attr_nlsw, residence_attr_nlsw)\n",
    "\n",
    "basic_attr = ['person_id', 'year', 'age']\n",
    "column_name_list = basic_attr + total_event_list\n",
    "\n",
    "# year range\n",
    "inv_start_year = 1968\n",
    "inv_end_year = 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到数据集存在的life_event_n\n",
    "## 更改数据集列名为直接命名，而非life_event_n\n",
    "## 运行这段前先运行前一段，之后还需要再次运行前一段（life_event_map的改变 & person_year_info0的含义变化）才能运行后一段\n",
    "person_year_info = pd.read_csv('nlsw-person-year.csv')\n",
    "basic_attr = ['person_id', 'year', 'age']\n",
    "stable_attr = ['occu_change', 'industry_change', 'income_quantile_upward', 'income_quantile_downward']\n",
    "raw_lfe_list = [i for i in list(person_year_info.columns) if i.startswith('life_event')]\n",
    "new_lde_list = list(map(lambda x: life_event_map[x], raw_lfe_list))\n",
    "person_year_info.columns = basic_attr+stable_attr+new_lde_list\n",
    "person_year_info.to_csv('nlsw-person-year-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_lfe_list = [i for i in list(person_year_info.columns) if i.startswith('life_event')]\n",
    "raw_lfe_list = [i for i in list(person_year_info0.columns) if i.startswith('life_event')]\n",
    "new_lde_list = list(map(lambda x: life_event_map[x], raw_lfe_list)) # get real exist event list\n",
    "\n",
    "drop_list = ['married spouse present_to_married spouse absent',\n",
    " 'married spouse absent_to_married spouse present',\n",
    " 'married spouse present_to_spouse absent, reason unknown',\n",
    " 'spouse absent, reason unknown_to_married spouse present',]\n",
    "df0 = person_year_info.drop(drop_list, axis=1)\n",
    "# migration\n",
    "df0['migration'] = df0[res_event_list].sum(axis=1)\n",
    "df1 = df0.drop(res_event_list, axis=1)\n",
    "# marrital status\n",
    "raw_lfe_list = [i for i in list(person_year_info0.columns) if i.startswith('life_event')]\n",
    "new_lde_list = list(map(lambda x: life_event_map[x], raw_lfe_list))\n",
    "new_mar_event_list = list(set(mar_event_list).intersection(set(new_lde_list))) # real exist mar event\n",
    "\n",
    "single_couple = [i for i in list(df1.columns) if i.endswith('married spouse present')]+[i for i in list(df1.columns) if i.endswith('married spouse absent')]\n",
    "df1['marrital_status-single_to_couple'] = df1[single_couple].sum(axis=1)\n",
    "couple_single = [i for i in list(df1.columns) if i.startswith('married spouse present')]+['spouse absent, reason unknown_to_separate']+[i for i in list(df1.columns) if i.startswith('married spouse absent')]\n",
    "df1['marrital_status-couple_to_single'] = df1[couple_single].sum(axis=1)\n",
    "single_single = [i for i in new_mar_event_list if i not in drop_list+single_couple+couple_single] \n",
    "df1['marrital_status-single_to_single'] = df1[single_single].sum(axis=1)\n",
    "df2 = df1.drop(single_couple+couple_single+single_single, axis=1)\n",
    "df2.to_csv('nlsw-person-year-combine.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlsy79\n",
    "person_year_info = pd.read_csv('nlsy-person-year-2.csv')\n",
    "person_year_info0 = pd.read_csv('nlsy-person-year.csv')\n",
    "stable_attr = ['occu_change', 'industry_change', 'income_quantile_upward', 'income_quantile_downward']\n",
    "marriage_attr_nlsw = [\n",
    "\t'never married',\n",
    "    'married',\n",
    "    'seperated',\n",
    "    'divorced',\n",
    "    'remarried',\n",
    "    'widowed']\n",
    "residence_attr_nlsw = [\n",
    "    'not in SMSA',\n",
    "    'SMSA, not in central city',\n",
    "    'SMSE,central city not known',\n",
    "    'SMSA, in central city']\n",
    "total_event_list, life_event_n_list, life_event_map, mar_event_list, res_event_list = event_creator(stable_attr, marriage_attr_nlsw, residence_attr_nlsw)\n",
    "\n",
    "basic_attr = ['person_id', 'year', 'age']\n",
    "column_name_list = basic_attr + total_event_list\n",
    "\n",
    "# year range\n",
    "inv_start_year = 1979\n",
    "inv_end_year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到数据集存在的life_event_n\n",
    "## 更改数据集列名为直接命名，而非life_event_n\n",
    "## 运行这段前先运行前一段，之后还需要再次运行前一段（life_event_map的改变 & person_year_info0的含义变化）才能运行后一段\n",
    "person_year_info = pd.read_csv('nlsy-person-year.csv')\n",
    "basic_attr = ['person_id', 'year', 'age']\n",
    "stable_attr = ['occu_change', 'industry_change', 'income_quantile_upward', 'income_quantile_downward']\n",
    "raw_lfe_list = [i for i in list(person_year_info.columns) if i.startswith('life_event')]\n",
    "new_lde_list = list(map(lambda x: life_event_map[x], raw_lfe_list))\n",
    "person_year_info.columns = basic_attr+stable_attr+new_lde_list\n",
    "person_year_info.to_csv('nlsy-person-year-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_lfe_list = [i for i in list(person_year_info.columns) if i.startswith('life_event')]\n",
    "raw_lfe_list = [i for i in list(person_year_info0.columns) if i.startswith('life_event')]\n",
    "new_lde_list = list(map(lambda x: life_event_map[x], raw_lfe_list)) # get real exist event list\n",
    "\n",
    "df0 = person_year_info\n",
    "# migration\n",
    "# Part 1: central_nocentral\n",
    "central_nocentral = ['SMSA, in central city_to_SMSA, not in central city',\n",
    "'SMSE,central city not known_to_SMSA, not in central city']\n",
    "df0['central_nocentral'] = df0[central_nocentral].sum(axis=1)\n",
    "\n",
    "# Part 2: nocentral_central\n",
    "nocentral_central = ['SMSA, not in central city_to_SMSA, in central city',\n",
    "'SMSA, not in central city_to_SMSE,central city not known',\n",
    "'not in SMSA_to_SMSE,central city not known',]\n",
    "df0['nocentral_central'] = df0[nocentral_central].sum(axis=1)\n",
    "# Part 3: other_migration\n",
    "new_res_event_list = list(set(res_event_list).intersection(set(new_lde_list))) # real exist res event\n",
    "other_migration = [i for i in new_res_event_list if i not in nocentral_central+central_nocentral] \n",
    "df0['other_migration']=df0[other_migration].sum(axis=1)\n",
    "\n",
    "df1 = df0.drop(new_res_event_list, axis=1)\n",
    "# marrital status\n",
    "new_mar_event_list = list(set(mar_event_list).intersection(set(new_lde_list))) # real exist mar event\n",
    "\n",
    "single_couple = [i for i in list(df1.columns) if i.endswith('to_married')]\n",
    "df1['marrital_status-single_to_couple'] = df1[single_couple].sum(axis=1)\n",
    "\n",
    "couple_single = [i for i in list(df1.columns) if i.startswith('married_to')]\n",
    "df1['marrital_status-couple_to_single'] = df1[couple_single].sum(axis=1)\n",
    "\n",
    "\n",
    "single_single = [i for i in new_mar_event_list if i not in single_couple+couple_single] \n",
    "df1['marrital_status-single_to_single'] = df1[single_single].sum(axis=1)\n",
    "\n",
    "df2 = df1.drop(single_couple+couple_single+single_single, axis=1)\n",
    "df2.to_csv('nlsy-person-year-combine.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlsm\n",
    "person_year_info = pd.read_csv('nlsm-person-year-2.csv')\n",
    "person_year_info0 = pd.read_csv('nlsm-person-year.csv')\n",
    "stable_attr = ['occu_change', 'industry_change', 'income_quantile_upward', 'income_quantile_downward']\n",
    "marriage_attr_nlsw = [\n",
    "    'married, spouse present',\n",
    "    'married, spouse absent',\n",
    "    'widowed',\n",
    "    'divorced',\n",
    "    'separated',\n",
    "    'never married']\n",
    "residence_attr_nlsw = [\n",
    "    'non-south',\n",
    "    'south']\n",
    "total_event_list, life_event_n_list, life_event_map, mar_event_list, res_event_list = event_creator(stable_attr, marriage_attr_nlsw, residence_attr_nlsw)\n",
    "\n",
    "basic_attr = ['person_id', 'year', 'age']\n",
    "column_name_list = basic_attr + total_event_list\n",
    "\n",
    "# year range\n",
    "inv_start_year = 1966\n",
    "inv_end_year = 1981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到数据集存在的life_event_n\n",
    "## 更改数据集列名为直接命名，而非life_event_n\n",
    "## 运行这段前先运行前一段，之后还需要再次运行前一段（life_event_map的改变 & person_year_info0的含义变化）才能运行后一段\n",
    "person_year_info = pd.read_csv('nlsm-person-year.csv')\n",
    "basic_attr = ['person_id', 'year', 'age']\n",
    "stable_attr = ['occu_change', 'industry_change', 'income_quantile_upward', 'income_quantile_downward']\n",
    "raw_lfe_list = [i for i in list(person_year_info.columns) if i.startswith('life_event')]\n",
    "new_lde_list = list(map(lambda x: life_event_map[x], raw_lfe_list))\n",
    "person_year_info.columns = basic_attr+stable_attr+new_lde_list\n",
    "person_year_info.to_csv('nlsm-person-year-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_lfe_list = [i for i in list(person_year_info.columns) if i.startswith('life_event')]\n",
    "raw_lfe_list = [i for i in list(person_year_info0.columns) if i.startswith('life_event')]\n",
    "new_lde_list = list(map(lambda x: life_event_map[x], raw_lfe_list)) # get real exist event list\n",
    "\n",
    "drop_list = ['married, spouse present_to_married, spouse absent',\n",
    " 'married, spouse absent_to_married, spouse present',]\n",
    "df0 = person_year_info.drop(drop_list, axis=1)\n",
    "# migration\n",
    "df0['migration'] = df0[res_event_list].sum(axis=1)\n",
    "df1 = df0.drop(res_event_list, axis=1)\n",
    "# marrital status\n",
    "raw_lfe_list = [i for i in list(person_year_info0.columns) if i.startswith('life_event')]\n",
    "new_lde_list = list(map(lambda x: life_event_map[x], raw_lfe_list))\n",
    "new_mar_event_list = list(set(mar_event_list).intersection(set(new_lde_list))) # real exist mar event\n",
    "\n",
    "single_couple = [i for i in list(df1.columns) if i.endswith('married, spouse present')]+[i for i in list(df1.columns) if i.endswith('married, spouse absent')]\n",
    "df1['marrital_status-single_to_couple'] = df1[single_couple].sum(axis=1)\n",
    "\n",
    "couple_single = [i for i in list(df1.columns) if i.startswith('married, spouse present')]+[i for i in list(df1.columns) if i.startswith('married, spouse absent')]\n",
    "df1['marrital_status-couple_to_single'] = df1[couple_single].sum(axis=1)\n",
    "\n",
    "single_single = [i for i in new_mar_event_list if i not in drop_list+single_couple+couple_single] \n",
    "df1['marrital_status-single_to_single'] = df1[single_single].sum(axis=1)\n",
    "\n",
    "df2 = df1.drop(single_couple+couple_single+single_single, axis=1)\n",
    "df2.to_csv('nlsm-person-year-combine.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psid\n",
    "person_year_info = pd.read_csv('psid-person-year-2.csv')\n",
    "person_year_info0 = pd.read_csv('psid-person-year.csv')\n",
    "stable_attr = ['occu_change', 'industry_change', 'income_quantile_upward', 'income_quantile_downward']\n",
    "marriage_attr_nlsw = [\n",
    "\t'married',\n",
    "    'widowed',\n",
    "    'divorced',\n",
    "    'separated',\n",
    "    'never married']\n",
    "residence_attr_nlsw = [\n",
    "    'northeast',\n",
    "    'north central',\n",
    "    'south',\n",
    "    'west',\n",
    "    'Alaska, Hawaii',\n",
    "    'Foreign country']\n",
    "total_event_list, life_event_n_list, life_event_map, mar_event_list, res_event_list = event_creator(stable_attr, marriage_attr_nlsw, residence_attr_nlsw)\n",
    "\n",
    "basic_attr = ['person_id', 'year', 'age']\n",
    "column_name_list = basic_attr + total_event_list\n",
    "\n",
    "# year range\n",
    "inv_start_year = 1968\n",
    "inv_end_year = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到数据集存在的life_event_n\n",
    "## 更改数据集列名为直接命名，而非life_event_n\n",
    "## 运行这段前先运行前一段，之后还需要再次运行前一段（life_event_map的改变 & person_year_info0的含义变化）才能运行后一段\n",
    "person_year_info = pd.read_csv('psid-person-year.csv')\n",
    "basic_attr = ['person_id', 'year', 'age']\n",
    "stable_attr = ['occu_change', 'industry_change', 'income_quantile_upward', 'income_quantile_downward']\n",
    "raw_lfe_list = [i for i in list(person_year_info.columns) if i.startswith('life_event')]\n",
    "new_lde_list = list(map(lambda x: life_event_map[x], raw_lfe_list))\n",
    "person_year_info.columns = basic_attr+stable_attr+new_lde_list\n",
    "person_year_info.to_csv('psid-person-year-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_lfe_list = [i for i in list(person_year_info.columns) if i.startswith('life_event')]\n",
    "raw_lfe_list = [i for i in list(person_year_info0.columns) if i.startswith('life_event')]\n",
    "new_lde_list = list(map(lambda x: life_event_map[x], raw_lfe_list)) # get real exist event list\n",
    "\n",
    "df0 = person_year_info\n",
    "# migration\n",
    "new_res_event_list = list(set(res_event_list).intersection(set(new_lde_list))) # real exist mar event\n",
    "df0['migration'] = df0[new_res_event_list].sum(axis=1)\n",
    "df1 = df0.drop(new_res_event_list, axis=1)\n",
    "# marrital status\n",
    "raw_lfe_list = [i for i in list(person_year_info0.columns) if i.startswith('life_event')]\n",
    "new_lde_list = list(map(lambda x: life_event_map[x], raw_lfe_list))\n",
    "new_mar_event_list = list(set(mar_event_list).intersection(set(new_lde_list))) # real exist mar event\n",
    "\n",
    "single_couple = [i for i in list(df1.columns) if i.endswith('to_married')]\n",
    "df1['marrital_status-single_to_couple'] = df1[single_couple].sum(axis=1)\n",
    "\n",
    "couple_single = [i for i in list(df1.columns) if i.startswith('married_to')]\n",
    "df1['marrital_status-couple_to_single'] = df1[couple_single].sum(axis=1)\n",
    "\n",
    "single_single = [i for i in new_mar_event_list if i not in single_couple+couple_single] \n",
    "df1['marrital_status-single_to_single'] = df1[single_single].sum(axis=1)\n",
    "\n",
    "df2 = df1.drop(single_couple+couple_single+single_single, axis=1)\n",
    "df2.to_csv('psid-person-year-combine.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转化industry code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nlsy_imputed.json') as json_file:\n",
    "    people_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取出以年为横坐标的数据，以求每一年的总体分布\n",
    "# nlsw\n",
    "# inv_start_year = 1968\n",
    "# inv_end_year = 2003\n",
    "# nlsm\n",
    "# inv_start_year = 1966\n",
    "# inv_end_year = 1981\n",
    "# nlsy\n",
    "inv_start_year = 1979\n",
    "inv_end_year = 2018\n",
    "# # psid\n",
    "# inv_start_year = 1968\n",
    "# inv_end_year = 2019\n",
    "df_list = []\n",
    "for idx, person in enumerate(people_dict):\n",
    "    if person['career_sequence_statistics']['career_length']!=0:\n",
    "        pid = people_dict[idx]['person_id']\n",
    "        s_start_year = person['life_sequence'][0]['year']\n",
    "        s_end_year = person['life_sequence'][-1]['year']\n",
    "        idx_start = s_start_year-inv_start_year\n",
    "        idx_end = s_end_year-inv_start_year       \n",
    "        df0 = pd.DataFrame(person['life_sequence'], index=range(idx_start, idx_end+1))[['occupation']].rename({'occupation': pid}, axis=1)\n",
    "        df_list.append(df0)\n",
    "df_people_occu = pd.concat(df_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people_occu = df_people_occu.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlsw(1968)\n",
    "# 68-93: 60 codes\n",
    "w_60_start = 0\n",
    "w_60_end = 1994-1968\n",
    "bin_60_3 = [1,195,199,222,249,290,300,370,379,395,400,545,600,775,800,804,809,890,900,905,959,985,994,995]\n",
    "# 95-01: 90 codes\n",
    "w_90_start = 1995-1968\n",
    "w_90_end = 2002-1968\n",
    "bin_90_3 = [3,22,37,42,199,202,235,242,285,302,389,402,407,412,427,432,469,472,476,484,499,502,699,702,889,996,997,998]\n",
    "# 03: 00 codes\n",
    "w_00 = 2003-1968\n",
    "bin_00_3 = [1,43,49,95,99,124,129,156,159,196,199,206,209,215,219,255,259,296,299,354,359,365,369,395,399,416,419,425,429,465,469,496,499,593,599,613,619,694,699,762,769,896,899,975,983,984,996,997,998]\n",
    "\n",
    "# nlsy(1979)\n",
    "# 79-00: 3 digit, 70 code,\n",
    "y_70_start = 0\n",
    "y_70_end = 2001-1979\n",
    "bin_70_3 = [1 , 195,200 , 245,259 , 285,300 , 395, 400 , 575,600 , 715,739 , 785,800 , 802,820 , 824,900 , 965, 979 , 984]\n",
    "# 02: 3-digit, 00 code\n",
    "y_00_3_start = 2002-1979\n",
    "y_00_3_end = 2003-1979\n",
    "\n",
    "# 04-18: 4 digit, 00 code\n",
    "y_00_4_start = 2004-1979\n",
    "y_00_4_end = 2018-1979\n",
    "bin_00_4 = [10 , 430, 500 -1, 950,1000-1 , 1240,1300 -1, 1560,1600 -1, 1760,1800 -1, 1860,1900 -1, 1960,2000-1 , 2060, 2100 -1, 2150,2200 -1, 2340,2400 -1, 2550, 2600 -1, 2760,2800 -1, 2960,3000-1 , 3260, 3300 -1, 3650,3700 -1, 3950,4000-1 , 4160,4200 -1, 4250,4300 -1, 4430,4459,4460, 4500 -1, 4650,4700 -1, 4960,5000-1 , 5930,6000-1 , 6130,6200 -1, 6940,7000-1 , 7620,7700 -1, 7750,7800 -1, 7850,7900 -1, 8960,9000-1 , 9750,9800 -1, 9830,9839,9840,9949,9950,9989,9990]\n",
    "\n",
    "# nlsm(1966)\n",
    "# 3-digit 60codes\n",
    "\n",
    "# psid更新过的occupation(1968)\n",
    "# 1968-2001: 1970 3-digit code, \n",
    "p_70_start = 0\n",
    "p_70_end = 2001-1968\n",
    "# 2002-2015: 2000 3-digit code,\n",
    "p_00_start = 2002-1968\n",
    "p_00_end = 2016-1968\n",
    "# 2017-2019: 2010 4-digit code\n",
    "p_10_start = 2017-1968\n",
    "p_10_end = 2019-1968\n",
    "bin_10_4 = [10 , 430, 500 -1, 950,1000-1 , 1240,1300 -1, 1560,1600 -1, 1965,2000-1 , 2060, 2100 -1, 2160,2200 -1, 2550, 2600 -1, 2960,3000-1 , 3540, 3600 -1, 3650,3700 -1, 3955,4000-1 , 4160,4200 -1, 4250,4300 -1, 4650,4700 -1, 4965,5000-1 , 5940,6005-1 , 6130,6200 -1, 6940,7700-1 , 8965,9000-1 , 9750,9800 -1, 9830,9998,9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据quantile——point划分level\n",
    "df_level_list = []\n",
    "for i in range(y_70_start, y_70_end+1):\n",
    "    df = pd.DataFrame(pd.cut(df_people_occu.loc[i].astype(float), bin_70_3,include_lowest=True))\n",
    "    df_level_list.append(df)\n",
    "for i in range(y_00_3_start, y_00_3_end+1):\n",
    "    df = pd.DataFrame(pd.cut(df_people_occu.loc[i].astype(float), bin_00_3,include_lowest=True))\n",
    "    df_level_list.append(df)\n",
    "# i = y_00\n",
    "# for i in range(df_people_occu.shape[0]):\n",
    "#     df = pd.DataFrame(pd.cut(df_people_occu.loc[i].astype(float), bin_70_3,include_lowest=True))\n",
    "#     df_level_list.append(df)\n",
    "for i in range(y_00_4_start, y_00_4_end+1):\n",
    "    df = pd.DataFrame(pd.cut(df_people_occu.loc[i].astype(float), bin_00_4,include_lowest=True))\n",
    "    df_level_list.append(df)\n",
    "df_people_occu_level = pd.concat(df_level_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>(4699.0, 4960.0]</td>\n",
       "      <td>(4699.0, 4960.0]</td>\n",
       "      <td>(4699.0, 4960.0]</td>\n",
       "      <td>(4699.0, 4960.0]</td>\n",
       "      <td>(4699.0, 4960.0]</td>\n",
       "      <td>(4699.0, 4960.0]</td>\n",
       "      <td>(4699.0, 4960.0]</td>\n",
       "      <td>(3999.0, 4160.0]</td>\n",
       "      <td>(3999.0, 4160.0]</td>\n",
       "      <td>(3999.0, 4160.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(200.0, 245.0]</td>\n",
       "      <td>(200.0, 245.0]</td>\n",
       "      <td>(200.0, 245.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(900.0, 965.0]</td>\n",
       "      <td>(900.0, 965.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>(4499.0, 4650.0]</td>\n",
       "      <td>(4499.0, 4650.0]</td>\n",
       "      <td>(4499.0, 4650.0]</td>\n",
       "      <td>(4299.0, 4430.0]</td>\n",
       "      <td>(4299.0, 4430.0]</td>\n",
       "      <td>(4299.0, 4430.0]</td>\n",
       "      <td>(4299.0, 4430.0]</td>\n",
       "      <td>(4299.0, 4430.0]</td>\n",
       "      <td>(4299.0, 4430.0]</td>\n",
       "      <td>(2999.0, 3260.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(259.0, 285.0]</td>\n",
       "      <td>(259.0, 285.0]</td>\n",
       "      <td>(259.0, 285.0]</td>\n",
       "      <td>(259.0, 285.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(2599.0, 2760.0]</td>\n",
       "      <td>(2599.0, 2760.0]</td>\n",
       "      <td>(2599.0, 2760.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12681</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(739.0, 785.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12682</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(200.0, 245.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12684</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12685</th>\n",
       "      <td>(900.0, 965.0]</td>\n",
       "      <td>(900.0, 965.0]</td>\n",
       "      <td>(900.0, 965.0]</td>\n",
       "      <td>(900.0, 965.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12686</th>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12321 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0               1               2               3   \\\n",
       "1      (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]   \n",
       "2      (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]   \n",
       "3      (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]  (200.0, 245.0]   \n",
       "4                 NaN             NaN             NaN  (259.0, 285.0]   \n",
       "5      (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]   \n",
       "...               ...             ...             ...             ...   \n",
       "12681             NaN  (739.0, 785.0]  (400.0, 575.0]  (400.0, 575.0]   \n",
       "12682             NaN  (600.0, 715.0]  (600.0, 715.0]  (600.0, 715.0]   \n",
       "12684             NaN             NaN             NaN             NaN   \n",
       "12685  (900.0, 965.0]  (900.0, 965.0]  (900.0, 965.0]  (900.0, 965.0]   \n",
       "12686  (600.0, 715.0]  (600.0, 715.0]  (600.0, 715.0]  (400.0, 575.0]   \n",
       "\n",
       "                   4               5               6               7   \\\n",
       "1      (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]   \n",
       "2      (300.0, 395.0]  (0.999, 195.0]  (300.0, 395.0]  (0.999, 195.0]   \n",
       "3      (200.0, 245.0]  (200.0, 245.0]  (300.0, 395.0]  (300.0, 395.0]   \n",
       "4      (259.0, 285.0]  (259.0, 285.0]  (259.0, 285.0]  (300.0, 395.0]   \n",
       "5      (0.999, 195.0]  (0.999, 195.0]  (0.999, 195.0]  (0.999, 195.0]   \n",
       "...               ...             ...             ...             ...   \n",
       "12681  (0.999, 195.0]  (400.0, 575.0]             NaN             NaN   \n",
       "12682  (600.0, 715.0]  (200.0, 245.0]             NaN             NaN   \n",
       "12684  (400.0, 575.0]  (400.0, 575.0]             NaN             NaN   \n",
       "12685  (0.999, 195.0]  (0.999, 195.0]             NaN             NaN   \n",
       "12686  (400.0, 575.0]  (400.0, 575.0]  (600.0, 715.0]  (400.0, 575.0]   \n",
       "\n",
       "                   8               9   ...                30  \\\n",
       "1      (300.0, 395.0]  (300.0, 395.0]  ...    (9.999, 430.0]   \n",
       "2      (0.999, 195.0]  (0.999, 195.0]  ...  (4699.0, 4960.0]   \n",
       "3      (900.0, 965.0]  (900.0, 965.0]  ...  (4499.0, 4650.0]   \n",
       "4      (300.0, 395.0]  (300.0, 395.0]  ...    (9.999, 430.0]   \n",
       "5      (0.999, 195.0]  (0.999, 195.0]  ...               NaN   \n",
       "...               ...             ...  ...               ...   \n",
       "12681             NaN             NaN  ...               NaN   \n",
       "12682             NaN             NaN  ...               NaN   \n",
       "12684             NaN             NaN  ...               NaN   \n",
       "12685             NaN             NaN  ...               NaN   \n",
       "12686  (400.0, 575.0]  (400.0, 575.0]  ...               NaN   \n",
       "\n",
       "                     31                32                33                34  \\\n",
       "1        (9.999, 430.0]    (9.999, 430.0]    (9.999, 430.0]    (9.999, 430.0]   \n",
       "2      (4699.0, 4960.0]  (4699.0, 4960.0]  (4699.0, 4960.0]  (4699.0, 4960.0]   \n",
       "3      (4499.0, 4650.0]  (4499.0, 4650.0]  (4299.0, 4430.0]  (4299.0, 4430.0]   \n",
       "4        (9.999, 430.0]    (9.999, 430.0]    (9.999, 430.0]    (9.999, 430.0]   \n",
       "5                   NaN               NaN               NaN               NaN   \n",
       "...                 ...               ...               ...               ...   \n",
       "12681               NaN               NaN               NaN               NaN   \n",
       "12682               NaN               NaN               NaN               NaN   \n",
       "12684               NaN               NaN               NaN               NaN   \n",
       "12685               NaN               NaN               NaN               NaN   \n",
       "12686               NaN               NaN               NaN               NaN   \n",
       "\n",
       "                     35                36                37                38  \\\n",
       "1        (9.999, 430.0]    (9.999, 430.0]    (9.999, 430.0]    (9.999, 430.0]   \n",
       "2      (4699.0, 4960.0]  (4699.0, 4960.0]  (3999.0, 4160.0]  (3999.0, 4160.0]   \n",
       "3      (4299.0, 4430.0]  (4299.0, 4430.0]  (4299.0, 4430.0]  (4299.0, 4430.0]   \n",
       "4        (9.999, 430.0]    (9.999, 430.0]  (2599.0, 2760.0]  (2599.0, 2760.0]   \n",
       "5                   NaN               NaN               NaN               NaN   \n",
       "...                 ...               ...               ...               ...   \n",
       "12681               NaN               NaN               NaN               NaN   \n",
       "12682               NaN               NaN               NaN               NaN   \n",
       "12684               NaN               NaN               NaN               NaN   \n",
       "12685               NaN               NaN               NaN               NaN   \n",
       "12686               NaN               NaN               NaN               NaN   \n",
       "\n",
       "                     39  \n",
       "1        (9.999, 430.0]  \n",
       "2      (3999.0, 4160.0]  \n",
       "3      (2999.0, 3260.0]  \n",
       "4      (2599.0, 2760.0]  \n",
       "5                   NaN  \n",
       "...                 ...  \n",
       "12681               NaN  \n",
       "12682               NaN  \n",
       "12684               NaN  \n",
       "12685               NaN  \n",
       "12686               NaN  \n",
       "\n",
       "[12321 rows x 40 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_people_occu_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people_occu_level.to_csv('nlsy_industry_info.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算occu变化 包括绝对和相对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>(4699.0, 4960.0]</td>\n",
       "      <td>(4699.0, 4960.0]</td>\n",
       "      <td>(4699.0, 4960.0]</td>\n",
       "      <td>(4699.0, 4960.0]</td>\n",
       "      <td>(4699.0, 4960.0]</td>\n",
       "      <td>(4699.0, 4960.0]</td>\n",
       "      <td>(4699.0, 4960.0]</td>\n",
       "      <td>(3999.0, 4160.0]</td>\n",
       "      <td>(3999.0, 4160.0]</td>\n",
       "      <td>(3999.0, 4160.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(200.0, 245.0]</td>\n",
       "      <td>(200.0, 245.0]</td>\n",
       "      <td>(200.0, 245.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(900.0, 965.0]</td>\n",
       "      <td>(900.0, 965.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>(4499.0, 4650.0]</td>\n",
       "      <td>(4499.0, 4650.0]</td>\n",
       "      <td>(4499.0, 4650.0]</td>\n",
       "      <td>(4299.0, 4430.0]</td>\n",
       "      <td>(4299.0, 4430.0]</td>\n",
       "      <td>(4299.0, 4430.0]</td>\n",
       "      <td>(4299.0, 4430.0]</td>\n",
       "      <td>(4299.0, 4430.0]</td>\n",
       "      <td>(4299.0, 4430.0]</td>\n",
       "      <td>(2999.0, 3260.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(259.0, 285.0]</td>\n",
       "      <td>(259.0, 285.0]</td>\n",
       "      <td>(259.0, 285.0]</td>\n",
       "      <td>(259.0, 285.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(9.999, 430.0]</td>\n",
       "      <td>(2599.0, 2760.0]</td>\n",
       "      <td>(2599.0, 2760.0]</td>\n",
       "      <td>(2599.0, 2760.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(300.0, 395.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12681</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(739.0, 785.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12682</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(200.0, 245.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12684</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12685</th>\n",
       "      <td>(900.0, 965.0]</td>\n",
       "      <td>(900.0, 965.0]</td>\n",
       "      <td>(900.0, 965.0]</td>\n",
       "      <td>(900.0, 965.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>(0.999, 195.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12686</th>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(600.0, 715.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>(400.0, 575.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12321 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0               1               2               3  \\\n",
       "1      (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]   \n",
       "2      (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]   \n",
       "3      (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]  (200.0, 245.0]   \n",
       "4                 NaN             NaN             NaN  (259.0, 285.0]   \n",
       "5      (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]   \n",
       "...               ...             ...             ...             ...   \n",
       "12681             NaN  (739.0, 785.0]  (400.0, 575.0]  (400.0, 575.0]   \n",
       "12682             NaN  (600.0, 715.0]  (600.0, 715.0]  (600.0, 715.0]   \n",
       "12684             NaN             NaN             NaN             NaN   \n",
       "12685  (900.0, 965.0]  (900.0, 965.0]  (900.0, 965.0]  (900.0, 965.0]   \n",
       "12686  (600.0, 715.0]  (600.0, 715.0]  (600.0, 715.0]  (400.0, 575.0]   \n",
       "\n",
       "                    4               5               6               7  \\\n",
       "1      (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]  (300.0, 395.0]   \n",
       "2      (300.0, 395.0]  (0.999, 195.0]  (300.0, 395.0]  (0.999, 195.0]   \n",
       "3      (200.0, 245.0]  (200.0, 245.0]  (300.0, 395.0]  (300.0, 395.0]   \n",
       "4      (259.0, 285.0]  (259.0, 285.0]  (259.0, 285.0]  (300.0, 395.0]   \n",
       "5      (0.999, 195.0]  (0.999, 195.0]  (0.999, 195.0]  (0.999, 195.0]   \n",
       "...               ...             ...             ...             ...   \n",
       "12681  (0.999, 195.0]  (400.0, 575.0]             NaN             NaN   \n",
       "12682  (600.0, 715.0]  (200.0, 245.0]             NaN             NaN   \n",
       "12684  (400.0, 575.0]  (400.0, 575.0]             NaN             NaN   \n",
       "12685  (0.999, 195.0]  (0.999, 195.0]             NaN             NaN   \n",
       "12686  (400.0, 575.0]  (400.0, 575.0]  (600.0, 715.0]  (400.0, 575.0]   \n",
       "\n",
       "                    8               9  ...                30  \\\n",
       "1      (300.0, 395.0]  (300.0, 395.0]  ...    (9.999, 430.0]   \n",
       "2      (0.999, 195.0]  (0.999, 195.0]  ...  (4699.0, 4960.0]   \n",
       "3      (900.0, 965.0]  (900.0, 965.0]  ...  (4499.0, 4650.0]   \n",
       "4      (300.0, 395.0]  (300.0, 395.0]  ...    (9.999, 430.0]   \n",
       "5      (0.999, 195.0]  (0.999, 195.0]  ...               NaN   \n",
       "...               ...             ...  ...               ...   \n",
       "12681             NaN             NaN  ...               NaN   \n",
       "12682             NaN             NaN  ...               NaN   \n",
       "12684             NaN             NaN  ...               NaN   \n",
       "12685             NaN             NaN  ...               NaN   \n",
       "12686  (400.0, 575.0]  (400.0, 575.0]  ...               NaN   \n",
       "\n",
       "                     31                32                33                34  \\\n",
       "1        (9.999, 430.0]    (9.999, 430.0]    (9.999, 430.0]    (9.999, 430.0]   \n",
       "2      (4699.0, 4960.0]  (4699.0, 4960.0]  (4699.0, 4960.0]  (4699.0, 4960.0]   \n",
       "3      (4499.0, 4650.0]  (4499.0, 4650.0]  (4299.0, 4430.0]  (4299.0, 4430.0]   \n",
       "4        (9.999, 430.0]    (9.999, 430.0]    (9.999, 430.0]    (9.999, 430.0]   \n",
       "5                   NaN               NaN               NaN               NaN   \n",
       "...                 ...               ...               ...               ...   \n",
       "12681               NaN               NaN               NaN               NaN   \n",
       "12682               NaN               NaN               NaN               NaN   \n",
       "12684               NaN               NaN               NaN               NaN   \n",
       "12685               NaN               NaN               NaN               NaN   \n",
       "12686               NaN               NaN               NaN               NaN   \n",
       "\n",
       "                     35                36                37                38  \\\n",
       "1        (9.999, 430.0]    (9.999, 430.0]    (9.999, 430.0]    (9.999, 430.0]   \n",
       "2      (4699.0, 4960.0]  (4699.0, 4960.0]  (3999.0, 4160.0]  (3999.0, 4160.0]   \n",
       "3      (4299.0, 4430.0]  (4299.0, 4430.0]  (4299.0, 4430.0]  (4299.0, 4430.0]   \n",
       "4        (9.999, 430.0]    (9.999, 430.0]  (2599.0, 2760.0]  (2599.0, 2760.0]   \n",
       "5                   NaN               NaN               NaN               NaN   \n",
       "...                 ...               ...               ...               ...   \n",
       "12681               NaN               NaN               NaN               NaN   \n",
       "12682               NaN               NaN               NaN               NaN   \n",
       "12684               NaN               NaN               NaN               NaN   \n",
       "12685               NaN               NaN               NaN               NaN   \n",
       "12686               NaN               NaN               NaN               NaN   \n",
       "\n",
       "                     39  \n",
       "1        (9.999, 430.0]  \n",
       "2      (3999.0, 4160.0]  \n",
       "3      (2999.0, 3260.0]  \n",
       "4      (2599.0, 2760.0]  \n",
       "5                   NaN  \n",
       "...                 ...  \n",
       "12681               NaN  \n",
       "12682               NaN  \n",
       "12684               NaN  \n",
       "12685               NaN  \n",
       "12686               NaN  \n",
       "\n",
       "[12321 rows x 40 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_people_occu_level = pd.read_csv('nlsy_industry_info.csv', index_col=['Unnamed: 0'])\n",
    "df_people_occu_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlsw(1968)\n",
    "# 68-93: 60 codes\n",
    "w_60_start = 0\n",
    "w_60_end = 1994-1968\n",
    "bin_60_3 = [0,195,199,222,249,290,300,370,379,395,400,545,600,775,800,804,809,890,900,905,959,985,994,995]\n",
    "# 95-01: 90 codes\n",
    "w_90_start = 1995-1968\n",
    "w_90_end = 2002-1968\n",
    "bin_90_3 = [3,22,37,42,199,202,235,242,285,302,389,402,407,412,427,432,469,472,476,484,499,502,699,702,889,996,997,998]\n",
    "# 03: 00 codes\n",
    "w_00 = 2003-1968\n",
    "bin_00_3 = [1,43,49,95,99,124,129,156,159,196,199,206,209,215,219,255,259,296,299,354,359,365,369,395,399,416,419,425,429,465,469,496,499,593,599,613,619,694,699,762,769,896,899,975,983,984,996,997,998]\n",
    "\n",
    "# nlsy(1979)\n",
    "# 79-00: 3 digit, 70 code,\n",
    "y_70_start = 0\n",
    "y_70_end = 2001-1979\n",
    "bin_70_3 = [1 , 195,200 , 245,259 , 285,300 , 395, 400 , 575,600 , 715,739 , 785,800 , 802,820 , 824,900 , 965, 979 , 984]\n",
    "# 02: 3-digit, 00 code\n",
    "y_00_3_start = 2002-1979\n",
    "y_00_3_end = 2003-1979\n",
    "\n",
    "# 04-18: 4 digit, 00 code\n",
    "y_00_4_start = 2004-1979\n",
    "y_00_4_end = 2018-1979\n",
    "bin_00_4 = [10 , 430, 500 -1, 950,1000-1 , 1240,1300 -1, 1560,1600 -1, 1760,1800 -1, 1860,1900 -1, 1960,2000-1 , 2060, 2100 -1, 2150,2200 -1, 2340,2400 -1, 2550, 2600 -1, 2760,2800 -1, 2960,3000-1 , 3260, 3300 -1, 3650,3700 -1, 3950,4000-1 , 4160,4200 -1, 4250,4300 -1, 4430,4459,4460, 4500 -1, 4650,4700 -1, 4960,5000-1 , 5930,6000-1 , 6130,6200 -1, 6940,7000-1 , 7620,7700 -1, 7750,7800 -1, 7850,7900 -1, 8960,9000-1 , 9750,9800 -1, 9830,9839,9840,9949,9950,9989,9990]\n",
    "\n",
    "# nlsm(1966)\n",
    "# 3-digit 60codes\n",
    "\n",
    "# psid更新过的occupation(1968)\n",
    "# 1968-2001: 1970 3-digit code, \n",
    "p_70_start = 0\n",
    "p_70_end = 2001-1968\n",
    "# 2002-2015: 2000 3-digit code,\n",
    "p_00_start = 2002-1968\n",
    "p_00_end = 2016-1968\n",
    "# 2017-2019: 2010 4-digit code\n",
    "p_10_start = 2017-1968\n",
    "p_10_end = 2019-1968\n",
    "bin_10_4 = [10 , 430, 500 -1, 950,1000-1 , 1240,1300 -1, 1560,1600 -1, 1965,2000-1 , 2060, 2100 -1, 2160,2200 -1, 2550, 2600 -1, 2960,3000-1 , 3540, 3600 -1, 3650,3700 -1, 3955,4000-1 , 4160,4200 -1, 4250,4300 -1, 4650,4700 -1, 4965,5000-1 , 5940,6005-1 , 6130,6200 -1, 6940,7700-1 , 8965,9000-1 , 9750,9800 -1, 9830,9998,9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people_occu_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绝对时间\n",
    "def ever_ind_change(row):\n",
    "    l0 = pd.Series([0 for i in range(len(row))])\n",
    "    row=row.dropna() #np.nan!=np.nan必须drop掉nan的影响\n",
    "    for idx, value in enumerate(row):\n",
    "        if idx==0 or idx==p_00_start or idx==p_10_start:\n",
    "            l0[idx]=-1\n",
    "        elif value!=row[idx-1]:\n",
    "            l0[idx]=1\n",
    "    return l0\n",
    "df_indu_wide = df_people_occu_level.apply(lambda x: ever_ind_change(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12681</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12682</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12684</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12685</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12686</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12321 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1   2   3   4   5   6   7   8   9   ...  30  31  32  33  34  35  \\\n",
       "1      -1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0  -1   0   \n",
       "2      -1   0   0   0   0   1   1   1   0   0  ...   0   0   0   0  -1   0   \n",
       "3      -1   0   0   1   0   0   1   0   1   0  ...   0   0   0   1  -1   0   \n",
       "4      -1   0   0   0   1   0   0   0   0   0  ...   0   0   0   0  -1   0   \n",
       "5      -1   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
       "12681  -1   1   0   1   1   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "12682  -1   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "12684  -1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "12685  -1   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "12686  -1   0   0   1   0   0   1   1   0   0  ...   0   0   0   0   0   0   \n",
       "\n",
       "       36  37  38  39  \n",
       "1       0   0   0   0  \n",
       "2       0   1   0   0  \n",
       "3       0   0   0   1  \n",
       "4       0   0   0   0  \n",
       "5       0   0   0   0  \n",
       "...    ..  ..  ..  ..  \n",
       "12681   0   0   0   0  \n",
       "12682   0   0   0   0  \n",
       "12684   0   0   0   0  \n",
       "12685   0   0   0   0  \n",
       "12686   0   0   0   0  \n",
       "\n",
       "[12321 rows x 40 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indu_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indu_wide.to_csv('nlsy_industry_change_abs.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相对时间\n",
    "def ever_ind_change(row):\n",
    "    row=row.dropna() #np.nan!=np.nan必须drop掉nan的影响\n",
    "    l1 = pd.Series([0 for i in range(len(row))])\n",
    "    for idx, value in enumerate(row):\n",
    "        if idx==0 or idx==p_00_start or idx==p_10_start:\n",
    "            l1[idx]=-1\n",
    "        elif value!=row[idx-1]:\n",
    "            l1[idx]=1\n",
    "    return l1\n",
    "df_indu_wide_r = df_people_occu_level.apply(lambda x: ever_ind_change(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indu_wide_r.to_csv('nlsy_industry_change_rela.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_ind_ch(x, inv_start_year):\n",
    "    if(len(x['person_id'])>0):\n",
    "        idx_start, idx_end = x['year'].min()-inv_start_year, x['year'].max()-inv_start_year\n",
    "        x['industry_change']=df_indu_wide"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec2bbd1a6bb0ffd7e2416afc0eb843ffc995c8a0c7f30368c51cc26c1d65c7be"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
